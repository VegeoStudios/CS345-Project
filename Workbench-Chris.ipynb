{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee19a590",
   "metadata": {},
   "source": [
    "-[Cross validation using grid search](https://www.kaggle.com/code/muhammetvarl/keras-multiclass-classification-cross-validation)\n",
    "\n",
    "-[resnet50Docs](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93ff7b10-6629-4374-9399-e2df4a0cb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import scipy.signal\n",
    "import keras\n",
    "import ipywidgets as widgets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "219b7d07-c5d3-4624-85ad-22391975a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89400, 5)\n",
      "(89400, 16, 16, 3)\n",
      "(595, 5)\n",
      "(595, 16, 16, 3)\n",
      "[[[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 99  27  79]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 76  20  55]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 76  20  55]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 97  65  41]\n",
      "   ...\n",
      "   [ 97  65  41]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 73  49  31]\n",
      "   ...\n",
      "   [ 73  49  31]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 73  49  31]\n",
      "   ...\n",
      "   [ 73  49  31]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 209  69]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 209  69]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 37  37  37]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [230  34  34]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [230  34  34]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 37  37  37]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [136  95  51]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 13  13  13]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.load('./Dataset1/sprites_labels.npy')\n",
    "sprites = np.load('./Dataset1/sprites.npy')\n",
    "\n",
    "print(data.shape)\n",
    "print(sprites.shape)\n",
    "\n",
    "selected_data = data[:894]\n",
    "selected_data = np.delete(selected_data, slice(244, 543), axis=0) #deletes duplicates\n",
    "print(selected_data.shape)\n",
    "\n",
    "selected_sprites = sprites[:894]\n",
    "selected_sprites = np.delete(selected_sprites, slice(244, 543), axis=0) #deletes duplicates\n",
    "print(selected_sprites.shape)\n",
    "\n",
    "data_with_mirrored = np.concatenate((selected_data, selected_data), axis=0)\n",
    "\n",
    "mirrored_sprites = np.flip(selected_sprites, axis=2)\n",
    "sprites_with_mirrored = np.concatenate((selected_sprites, mirrored_sprites), axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(selected_sprites[1])\n",
    "ax[1].imshow(mirrored_sprites[1]);\n",
    "\n",
    "print(sprites_with_mirrored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03821100-10bd-4767-bebd-f04bfb5d37e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sprites_with_mirrored, data_with_mirrored)\n",
    "\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, 5)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, 5)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "\n",
    "conv_result = scipy.signal.convolve2d(X_train[400, :, :, :1].reshape(16, 16), np.array([[1,2,1],[0,0,0],[-1,-2,-1]]).T)\n",
    "im = ax.imshow(conv_result, cmap='Greys')\n",
    "ax2.imshow(X_train[400, :, :, :1])\n",
    "ax.axis('off')\n",
    "fig.colorbar(im, ax=[ax, ax2]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17bf0d9f-481e-4ec2-b77a-9a0c06d5efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "conv_network = tf.keras.Sequential()\n",
    "\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Flatten())\n",
    "\n",
    "conv_network.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "conv_network.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data1 = np.load('./Dataset1/sprites_labels.npy')\n",
    "sprites1 = np.load('./Dataset1/sprites.npy')\n",
    "\n",
    "selected_labels = data1[:894]\n",
    "y = np.delete(selected_labels, slice(244, 543), axis=0)\n",
    "\n",
    "selected_sprites = sprites1[:894]\n",
    "X = np.delete(selected_sprites, slice(244, 543), axis=0)\n",
    "\n",
    "X = X.astype(np.float32) / 255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b004bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,3)),\n",
    "    #keras.layers.Conv2D(196, (3, 3), strides=(1,1), activation='relu', input_shape=(16,16,3)),\n",
    "    keras.layers.Flatten(input_shape=(16, 16, 3)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "]);\n",
    "\n",
    "#other activations functions tried include sigmoid and different orders of relu and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cca267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52014fd3-cadd-45b2-805c-dd325ee47c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.0023275e-20 1.4294558e-27 1.0873960e-08 1.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model(X_train[:1]).numpy()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "181fd53c-b0d8-43a9-80c5-21efb0b9377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b37e5b09-a018-4b7b-a0a1-cc6736fe2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.CategoricalCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea37ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.118095"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cd1453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "loss_fn1 = keras.losses.CategoricalFocalCrossentropy()\n",
    "loss_fn1(y_train[:1], predictions).numpy()\n",
    "'''\n",
    "\n",
    "#loss_fn2 = keras.losses.SparseCategoricalCrossentropy()\n",
    "#loss_fn2(y_train[:2], predictions).numpy()\n",
    "\n",
    "model.compile(optimizer='Adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "#Tried with RMSProp, SGD, Adadelta. Adam appears to have the most acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce19adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.4307 - loss: 37.6984 - val_accuracy: 0.8423 - val_loss: 4.9380\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7771 - loss: 4.5643 - val_accuracy: 0.8289 - val_loss: 0.9933\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8593 - loss: 0.7709 - val_accuracy: 0.8993 - val_loss: 0.3550\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9058 - loss: 0.2980 - val_accuracy: 0.9161 - val_loss: 0.2957\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8924 - loss: 0.2904 - val_accuracy: 0.9295 - val_loss: 0.2057\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9166 - loss: 0.1993 - val_accuracy: 0.9228 - val_loss: 0.2300\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9422 - loss: 0.1585 - val_accuracy: 0.9497 - val_loss: 0.1726\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9320 - loss: 0.1450 - val_accuracy: 0.9564 - val_loss: 0.1536\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9665 - loss: 0.0767 - val_accuracy: 0.9597 - val_loss: 0.1571\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9638 - loss: 0.0738 - val_accuracy: 0.9631 - val_loss: 0.1420\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9651 - loss: 0.0732 - val_accuracy: 0.9564 - val_loss: 0.1467\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9678 - loss: 0.0709 - val_accuracy: 0.9698 - val_loss: 0.1246\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9799 - loss: 0.0541 - val_accuracy: 0.9664 - val_loss: 0.1311\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9785 - loss: 0.0518 - val_accuracy: 0.9664 - val_loss: 0.1208\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9739 - loss: 0.0706 - val_accuracy: 0.9698 - val_loss: 0.1151\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9777 - loss: 0.0517 - val_accuracy: 0.9732 - val_loss: 0.0965\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9838 - loss: 0.0399 - val_accuracy: 0.9799 - val_loss: 0.0876\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9744 - loss: 0.0653 - val_accuracy: 0.9732 - val_loss: 0.1036\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9882 - loss: 0.0310 - val_accuracy: 0.9765 - val_loss: 0.0944\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9832 - loss: 0.0491 - val_accuracy: 0.9799 - val_loss: 0.0878\n"
     ]
    }
   ],
   "source": [
    "historyConv = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "186cff56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_80\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_80\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2401</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">153,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_78 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m49\u001b[0m)       │         \u001b[38;5;34m1,372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_78 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2401\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_156 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m153,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_78 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_157 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466,277</span> (1.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m466,277\u001b[0m (1.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">155,425</span> (607.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m155,425\u001b[0m (607.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,852</span> (1.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m310,852\u001b[0m (1.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0854e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85, 1.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historyConv.history['accuracy'], label='Train')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0.85, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1af06fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - 8ms/step - accuracy: 0.9799 - loss: 0.0878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08784741163253784, 0.9798657894134521]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "867e603c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758],\n",
       "       [0.14884758, 0.14884758, 0.14884758, 0.14884758, 0.40460962],\n",
       "       [0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758],\n",
       "       [0.1488482 , 0.1488482 , 0.1488482 , 0.14885063, 0.4046047 ],\n",
       "       [0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model = keras.Sequential([model, keras.layers.Softmax()])\n",
    "probability_model(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4b46914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7375b2e072284c14969061d65555619d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Image index:', max=297), Output()), _dom_classes=('widge…"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "label_names = ['Character (FORWARD)', 'Monster', 'Food', 'Item', 'Character (SIDE)']\n",
    "index_slider = widgets.IntSlider(value=0, min=0, max=len(X_test)-1, description='Image index:')\n",
    "def show_image(index):\n",
    "    plt.imshow(X_test[index])\n",
    "    plt.show()\n",
    "    prediction = probability_model(X_test[index:index+1]).numpy()\n",
    "    print(f'Predicted label: {np.argmax(prediction)} ({label_names[np.argmax(prediction)]})')\n",
    "    print(f'Actual label: {np.argmax(y_test[index])} ({label_names[np.argmax(y_test[index])]})')\n",
    "    print('Predicted probabilities:')\n",
    "    print(f'    Character (FORWARD): {'%.2f' % (prediction[0][0] * 100)}%')\n",
    "    print(f'    Monster:             {'%.2f' % (prediction[0][1] * 100)}%')\n",
    "    print(f'    Food:                {'%.2f' % (prediction[0][2] * 100)}%')\n",
    "    print(f'    Item:                {'%.2f' % (prediction[0][3] * 100)}%')\n",
    "    print(f'    Character (SIDE):    {'%.2f' % (prediction[0][4] * 100)}%')\n",
    "widgets.interactive(show_image, index=index_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa7f7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4980 - loss: 1.2774\n",
      "Epoch 2/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7095 - loss: 0.7261\n",
      "Epoch 3/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8717 - loss: 0.3980\n",
      "Epoch 4/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9437 - loss: 0.2397\n",
      "Epoch 5/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1720\n",
      "Epoch 6/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9748 - loss: 0.1159\n",
      "Epoch 7/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9731 - loss: 0.1016\n",
      "Epoch 8/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0749\n",
      "Epoch 9/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9912 - loss: 0.0517\n",
      "Epoch 10/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0539\n",
      "Epoch 11/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0341\n",
      "Epoch 12/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0329\n",
      "Epoch 13/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0283\n",
      "Epoch 14/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0265\n",
      "Epoch 15/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0165\n",
      "Epoch 16/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0186\n",
      "Epoch 17/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0166\n",
      "Epoch 18/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0118\n",
      "Epoch 19/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0147\n",
      "Epoch 20/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0115\n",
      "Epoch 21/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0089\n",
      "Epoch 22/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0088\n",
      "Epoch 23/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 24/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0100\n",
      "Epoch 25/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "Epoch 26/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0054   \n",
      "Epoch 27/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 28/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 29/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Epoch 30/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 31/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 32/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0059\n",
      "Epoch 33/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 34/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 35/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 36/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 37/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 38/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 39/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 40/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 41/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 42/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 43/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 44/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 45/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 46/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 47/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 48/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0065\n",
      "Epoch 49/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 50/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017   \n",
      "Epoch 51/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 52/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 53/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016   \n",
      "Epoch 54/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 55/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 56/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 57/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 58/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 59/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 60/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0038   \n",
      "Epoch 61/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0050   \n",
      "Epoch 62/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 63/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 64/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.8745e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0010    \n",
      "Epoch 66/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.4937e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.5937e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.1624e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.0594e-04 \n",
      "Epoch 70/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9481e-04 \n",
      "Epoch 71/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.2866e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9225e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0036   \n",
      "Epoch 74/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.9420e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 76/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 77/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.6870e-04 \n",
      "Epoch 78/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2676e-04 \n",
      "Epoch 79/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5812e-04 \n",
      "Epoch 80/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.8642e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.5496e-04 \n",
      "Epoch 82/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.4481e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.7199e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.0018e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.7918e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 87/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 88/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2057e-04 \n",
      "Epoch 89/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7438e-04  \n",
      "Epoch 90/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8335e-04 \n",
      "Epoch 91/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6891e-04 \n",
      "Epoch 92/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5953e-04 \n",
      "Epoch 93/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3286e-04 \n",
      "Epoch 94/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4467e-04 \n",
      "Epoch 95/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4083e-04 \n",
      "Epoch 96/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4077e-04 \n",
      "Epoch 97/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.3608e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4823e-04 \n",
      "Epoch 99/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4155e-04  \n",
      "Epoch 100/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.3722e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7493e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.9833e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.0990e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.7377e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.5955e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.3207e-04 \n",
      "Epoch 107/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.0660e-04 \n",
      "Epoch 108/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.2634e-04 \n",
      "Epoch 109/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.7214e-04 \n",
      "Epoch 110/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5217e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.4307e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 113/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.4571e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.8846e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0295e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0193e-04 \n",
      "Epoch 117/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.0295e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.1815e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0400e-04 \n",
      "Epoch 120/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0002e-04 \n",
      "Epoch 121/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 122/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.2760e-04 \n",
      "Epoch 123/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8880e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1966e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.7597e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2168e-04 \n",
      "Epoch 127/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.9240e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1667e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3774e-04 \n",
      "Epoch 130/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9207e-04 \n",
      "Epoch 131/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.8101e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9694e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1108e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6748e-04 \n",
      "Epoch 135/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.5953e-05 \n",
      "Epoch 136/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.4386e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4717e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.9224e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2645e-04 \n",
      "Epoch 140/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.2741e-05\n",
      "Epoch 141/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6795e-04  \n",
      "Epoch 142/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7131e-04 \n",
      "Epoch 143/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2687e-04 \n",
      "Epoch 144/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3399e-04 \n",
      "Epoch 145/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1960e-04\n",
      "Epoch 146/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4938e-04\n",
      "Epoch 147/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 148/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0279   \n",
      "Epoch 149/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0262\n",
      "Epoch 150/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0171 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Accuracy:  0.9966386554621849\n",
      "0.976864 (0.015488) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.976864 (0.012298) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "0.972654 (0.012661) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.978969 (0.013332) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.976864 (0.015488) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "0.974759 (0.014301) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "0.978969 (0.016322) with: {'batch_size': 32, 'epochs': 150, 'optimizer': 'Adam'}\n",
      "0.981075 (0.013978) with: {'batch_size': 32, 'epochs': 150, 'optimizer': 'Adadelta'}\n",
      "0.974759 (0.014301) with: {'batch_size': 32, 'epochs': 150, 'optimizer': 'SGD'}\n",
      "0.978969 (0.011551) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.976864 (0.012298) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "0.976864 (0.016859) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.976864 (0.012298) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.981075 (0.012291) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "0.978991 (0.013315) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "0.978969 (0.011551) with: {'batch_size': 50, 'epochs': 150, 'optimizer': 'Adam'}\n",
      "0.978969 (0.011551) with: {'batch_size': 50, 'epochs': 150, 'optimizer': 'Adadelta'}\n",
      "0.976864 (0.012298) with: {'batch_size': 50, 'epochs': 150, 'optimizer': 'SGD'}\n",
      "0.968487 (0.011532) with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.976864 (0.010341) with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "0.970592 (0.007861) with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.978969 (0.011551) with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.978969 (0.011551) with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "0.978969 (0.013332) with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "0.976864 (0.010341) with: {'batch_size': 100, 'epochs': 150, 'optimizer': 'Adam'}\n",
      "0.981075 (0.012291) with: {'batch_size': 100, 'epochs': 150, 'optimizer': 'Adadelta'}\n",
      "0.978991 (0.011531) with: {'batch_size': 100, 'epochs': 150, 'optimizer': 'SGD'}\n",
      "Best: 0.981075 using {'batch_size': 32, 'epochs': 150, 'optimizer': 'Adadelta'}\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def create_model(optimizer=\"adam\"):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,3)))\n",
    "    model.add(keras.layers.Flatten(input_shape=(16, 16, 3)))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "   \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "'''\n",
    "param_grid = {\n",
    "    'epochs' : [50, 100, 150],\n",
    "    'batch_size' : [32, 50, 100],\n",
    "    'optimizer' : ['Adam', 'Adadelta', 'SGD']\n",
    "}\n",
    "\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_cv, param_distributions=param_grid, n_iter=15\n",
    ")\n",
    "\n",
    "random_model = random_search.fit(X,y)\n",
    "\n",
    "start = time()\n",
    "print(\n",
    "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
    "    % ((time() - start), 15)\n",
    ")\n",
    "report(random_search.cv_results_)\n",
    "'''\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'epochs' : [50, 100, 150],\n",
    "    'batch_size' : [32, 50, 100],\n",
    "    'optimizer' : ['Adam', 'Adadelta', 'SGD']\n",
    "}\n",
    "\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "grid = GridSearchCV(estimator=model_cv,  \n",
    "                    n_jobs=-1, \n",
    "                    verbose=1,\n",
    "                    cv=5,\n",
    "                    param_grid=param_grid)\n",
    "\n",
    "grid_cv_model = grid.fit(X_cv, y_cv,)\n",
    "\n",
    "y_pred = grid_cv_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \", np.mean(y_test == y_pred))\n",
    "\n",
    "means = grid_cv_model.cv_results_['mean_test_score'] # Mean of test scores\n",
    "stds = grid_cv_model.cv_results_['std_test_score'] # standard deviations of test scores\n",
    "params = grid_cv_model.cv_results_['params'] # parameters used\n",
    "# to print all scores, standard deviations and parameters used\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Printing the Best Parameters as a Result of Grid Search Cross Validation on the Screen\n",
    "print(\"Best: %f using %s\" % (grid_cv_model.best_score_, grid_cv_model.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eeb99aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4566 - loss: 1.3911\n",
      "Epoch 2/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6442 - loss: 0.9572\n",
      "Epoch 3/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8091 - loss: 0.6066\n",
      "Epoch 4/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.3689\n",
      "Epoch 5/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9322 - loss: 0.2696\n",
      "Epoch 6/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9715 - loss: 0.1506\n",
      "Epoch 7/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9757 - loss: 0.1359\n",
      "Epoch 8/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 0.0872\n",
      "Epoch 9/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9794 - loss: 0.0932\n",
      "Epoch 10/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0629\n",
      "Epoch 11/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 0.0529\n",
      "Epoch 12/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9868 - loss: 0.0569\n",
      "Epoch 13/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0474\n",
      "Epoch 14/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0285\n",
      "Epoch 15/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0257 \n",
      "Epoch 16/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0221 \n",
      "Epoch 17/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0230\n",
      "Epoch 18/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0214\n",
      "Epoch 19/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0153\n",
      "Epoch 20/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0178\n",
      "Epoch 21/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 0.0207\n",
      "Epoch 22/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0227 \n",
      "Epoch 23/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0123\n",
      "Epoch 24/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 25/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "Epoch 26/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0100\n",
      "Epoch 27/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0118\n",
      "Epoch 28/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0062\n",
      "Epoch 29/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 30/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0041 \n",
      "Epoch 31/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0059 \n",
      "Epoch 32/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0124 \n",
      "Epoch 33/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0094 \n",
      "Epoch 34/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0111\n",
      "Epoch 35/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0080\n",
      "Epoch 36/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0089\n",
      "Epoch 37/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0077\n",
      "Epoch 38/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0033   \n",
      "Epoch 39/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 40/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 41/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 42/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 43/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 44/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0042   \n",
      "Epoch 45/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0029 \n",
      "Epoch 46/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0072\n",
      "Epoch 47/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0049    \n",
      "Epoch 48/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 49/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0056\n",
      "Epoch 50/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 51/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 52/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 53/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 54/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 55/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 56/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0023     \n",
      "Epoch 57/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 58/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 59/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 60/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 61/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 62/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 63/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0025     \n",
      "Epoch 64/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 \n",
      "Epoch 65/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 66/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 \n",
      "Epoch 67/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0027     \n",
      "Epoch 68/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 69/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 70/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 71/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.9216e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.9883e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0017 \n",
      "Epoch 74/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0019    \n",
      "Epoch 75/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0019   \n",
      "Epoch 76/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0024     \n",
      "Epoch 77/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 78/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "Epoch 79/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.3557e-04 \n",
      "Epoch 80/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 81/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.4259e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.2390e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5308e-04  \n",
      "Epoch 84/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 \n",
      "Epoch 85/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 86/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 87/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2349e-04 \n",
      "Epoch 88/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0370e-04 \n",
      "Epoch 89/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0037     \n",
      "Epoch 90/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0029    \n",
      "Epoch 91/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 92/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 93/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0022     \n",
      "Epoch 94/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 95/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0027     \n",
      "Epoch 96/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 97/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
      "Epoch 98/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0016    \n",
      "Epoch 99/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017   \n",
      "Epoch 100/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7209e-04 \n",
      "Epoch 101/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2472e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 9.5496e-04 \n",
      "Epoch 103/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0148    \n",
      "Epoch 104/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0360\n",
      "Epoch 105/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0086\n",
      "Epoch 106/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Epoch 107/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 108/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0019\n",
      "Epoch 109/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 110/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013    \n",
      "Epoch 111/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.7525e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.5933e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0013  \n",
      "Epoch 114/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.7624e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.6537e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.0789e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 118/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 119/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.2772e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 121/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.1024e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.6159e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.1404e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.0121e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.3510e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.8005e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.2248e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3023e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.7495e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.6775e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.5069e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1608e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.7592e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 135/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.3765e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.0818e-04\n",
      "Epoch 137/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0019   \n",
      "Epoch 138/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6719e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8676e-04\n",
      "Epoch 140/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1368e-04\n",
      "Epoch 141/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0832e-04  \n",
      "Epoch 142/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.9515e-04\n",
      "Epoch 143/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 144/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.9768e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 146/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.2444e-04\n",
      "Epoch 147/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.4965e-04\n",
      "Epoch 148/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8921e-04\n",
      "Epoch 149/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5087e-04\n",
      "Epoch 150/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.0073e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5212 - loss: 1.2950\n",
      "Epoch 2/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.7113\n",
      "Epoch 3/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9281 - loss: 0.3210\n",
      "Epoch 4/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.2030\n",
      "Epoch 5/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9284 - loss: 0.1800\n",
      "Epoch 6/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9699 - loss: 0.1183\n",
      "Epoch 7/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9510 - loss: 0.1133\n",
      "Epoch 8/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 0.0821\n",
      "Epoch 9/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0653\n",
      "Epoch 10/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0474\n",
      "Epoch 11/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0460\n",
      "Epoch 12/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0319\n",
      "Epoch 13/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0250\n",
      "Epoch 14/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0243\n",
      "Epoch 15/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0252\n",
      "Epoch 16/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0253\n",
      "Epoch 17/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0163\n",
      "Epoch 18/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0134\n",
      "Epoch 19/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0113\n",
      "Epoch 20/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0083\n",
      "Epoch 21/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0075\n",
      "Epoch 22/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 23/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 24/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "Epoch 25/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0056  \n",
      "Epoch 26/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0076\n",
      "Epoch 27/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0090\n",
      "Epoch 28/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0090\n",
      "Epoch 29/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 30/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 31/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 32/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 33/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 34/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 35/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 36/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 37/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0026\n",
      "Epoch 38/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 39/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0028   \n",
      "Epoch 40/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 41/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 42/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 43/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 44/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 45/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018   \n",
      "Epoch 46/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 47/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 48/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 49/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 50/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 51/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 52/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 53/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 54/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 55/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 56/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0022   \n",
      "Epoch 57/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 58/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 59/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 60/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 61/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9587e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.1713e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 64/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7475e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.5325e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.4454e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.0003e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.3355e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.6200e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 71/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.5480e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.2727e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012    \n",
      "Epoch 74/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.1113e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 76/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.1849e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.1107e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9045e-04 \n",
      "Epoch 79/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025     \n",
      "Epoch 80/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0062    \n",
      "Epoch 81/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019    \n",
      "Epoch 82/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "Epoch 83/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.3509e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.5808e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.5140e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.4381e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0934e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.0916e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 90/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.5425e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.6997e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.9735e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4388e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.3242e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9899e-04 \n",
      "Epoch 96/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.3280e-04 \n",
      "Epoch 97/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.7766e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.6107e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2371e-04 \n",
      "Epoch 100/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6320e-04 \n",
      "Epoch 101/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9931e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.4777e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.8539e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.4891e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5611e-04 \n",
      "Epoch 106/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6204e-04 \n",
      "Epoch 107/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.6909e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.7619e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9074e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7473e-04 \n",
      "Epoch 111/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.5317e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.0491e-04  \n",
      "Epoch 113/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.5944e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1434e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3783e-04 \n",
      "Epoch 116/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.3653e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9332e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.0312e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.2662e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4649e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2569e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0516e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.1204e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3135e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1675e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5827e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0401e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.3094e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.3763e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.9425e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.4246e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.4283e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1624e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.2977e-04\n",
      "Epoch 135/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014   \n",
      "Epoch 136/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 137/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.6402e-04 \n",
      "Epoch 138/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.1800e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5594e-04 \n",
      "Epoch 140/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.2492e-04\n",
      "Epoch 141/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2257e-04 \n",
      "Epoch 142/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.8065e-04\n",
      "Epoch 143/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2705e-04\n",
      "Epoch 144/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3967e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3250e-05 \n",
      "Epoch 146/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4976e-05\n",
      "Epoch 147/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0614e-04 \n",
      "Epoch 148/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5835e-04\n",
      "Epoch 149/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2314e-04 \n",
      "Epoch 150/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0534e-04  \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4828 - loss: 1.2977\n",
      "Epoch 2/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7050 - loss: 0.7325\n",
      "Epoch 3/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.4283\n",
      "Epoch 4/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9186 - loss: 0.2778\n",
      "Epoch 5/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9388 - loss: 0.2091 \n",
      "Epoch 6/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9634 - loss: 0.1258\n",
      "Epoch 7/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 0.0977\n",
      "Epoch 8/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9851 - loss: 0.1085\n",
      "Epoch 9/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0607\n",
      "Epoch 10/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0545\n",
      "Epoch 11/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0374\n",
      "Epoch 12/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.0475\n",
      "Epoch 13/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0283\n",
      "Epoch 14/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0270\n",
      "Epoch 15/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0364\n",
      "Epoch 16/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0230\n",
      "Epoch 17/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0147\n",
      "Epoch 18/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0136 \n",
      "Epoch 19/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0146\n",
      "Epoch 20/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0117  \n",
      "Epoch 21/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0109\n",
      "Epoch 22/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0135\n",
      "Epoch 23/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0055\n",
      "Epoch 24/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0080\n",
      "Epoch 25/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 26/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 27/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 28/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0098\n",
      "Epoch 29/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0066\n",
      "Epoch 30/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 31/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 32/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 33/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 34/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0043 \n",
      "Epoch 35/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 36/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 37/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0073\n",
      "Epoch 38/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0051 \n",
      "Epoch 39/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 40/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 41/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0024   \n",
      "Epoch 42/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 43/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0090\n",
      "Epoch 44/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 45/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 46/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 47/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 48/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0018   \n",
      "Epoch 49/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 50/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 51/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 52/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0015    \n",
      "Epoch 53/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015   \n",
      "Epoch 54/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 55/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 56/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0013    \n",
      "Epoch 57/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.0607e-04 \n",
      "Epoch 58/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.3166e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0015   \n",
      "Epoch 60/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 61/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.8556e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.9307e-04 \n",
      "Epoch 63/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 64/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0018   \n",
      "Epoch 65/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 66/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.8823e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012    \n",
      "Epoch 68/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 69/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 70/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 71/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 72/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016     \n",
      "Epoch 73/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011    \n",
      "Epoch 74/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 75/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.7531e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.4784e-04 \n",
      "Epoch 77/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 78/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3206e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0014    \n",
      "Epoch 80/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012    \n",
      "Epoch 81/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 9.1881e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 83/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0011  \n",
      "Epoch 84/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.0978e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.7464e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 87/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.2833e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.7237e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0011    \n",
      "Epoch 90/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.7138e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.0250e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.8562e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.5789e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.0976e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.3734e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.1425e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 4.3730e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 6.0341e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.6979e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 8.2539e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 102/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0010    \n",
      "Epoch 103/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3599e-04\n",
      "Epoch 104/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0010   \n",
      "Epoch 105/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 106/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.5732e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0011    \n",
      "Epoch 108/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 109/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.4845e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.0927e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 112/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.0972e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.5334e-04\n",
      "Epoch 114/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011    \n",
      "Epoch 115/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0028  \n",
      "Epoch 116/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0012  \n",
      "Epoch 117/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 8.2860e-04\n",
      "Epoch 118/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 7.3034e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.3015e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.1006e-04 \n",
      "Epoch 121/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.6443e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0014  \n",
      "Epoch 123/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.9115e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.9402e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.8696e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.4894e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1735e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 129/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.7478e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.0102e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.2503e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.1893e-05\n",
      "Epoch 133/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.0815e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.7766e-04\n",
      "Epoch 135/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0529e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.7731e-05\n",
      "Epoch 137/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.6981e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4633e-04\n",
      "Epoch 139/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.4281e-04\n",
      "Epoch 140/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.9067e-04\n",
      "Epoch 141/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9023e-04\n",
      "Epoch 142/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.9777e-04\n",
      "Epoch 143/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.3881e-04\n",
      "Epoch 144/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3958e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.4281e-04\n",
      "Epoch 146/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.4430e-04\n",
      "Epoch 147/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4446e-04\n",
      "Epoch 148/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.0057e-04\n",
      "Epoch 149/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.6014e-04\n",
      "Epoch 150/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3703e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5255 - loss: 1.2663\n",
      "Epoch 2/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7305 - loss: 0.7121\n",
      "Epoch 3/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.4097\n",
      "Epoch 4/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9202 - loss: 0.2127\n",
      "Epoch 5/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9467 - loss: 0.1636\n",
      "Epoch 6/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.1048\n",
      "Epoch 7/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9804 - loss: 0.0735\n",
      "Epoch 8/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 0.0658\n",
      "Epoch 9/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0510\n",
      "Epoch 10/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.0558\n",
      "Epoch 11/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0214\n",
      "Epoch 12/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0290\n",
      "Epoch 13/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0200\n",
      "Epoch 14/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0216\n",
      "Epoch 15/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0141\n",
      "Epoch 16/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0204\n",
      "Epoch 17/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0162\n",
      "Epoch 18/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0127\n",
      "Epoch 19/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0124\n",
      "Epoch 20/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0123\n",
      "Epoch 21/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0091\n",
      "Epoch 22/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0089\n",
      "Epoch 23/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0073\n",
      "Epoch 24/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 25/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 26/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 27/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0078\n",
      "Epoch 28/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 29/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 30/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 31/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 32/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 33/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0024    \n",
      "Epoch 34/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 35/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Epoch 36/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0023   \n",
      "Epoch 37/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 38/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 39/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 40/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0064\n",
      "Epoch 41/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0044\n",
      "Epoch 42/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 43/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 44/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 45/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017   \n",
      "Epoch 46/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 47/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0044\n",
      "Epoch 48/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 49/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 50/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017   \n",
      "Epoch 51/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0037\n",
      "Epoch 52/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 53/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 54/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.3698e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 56/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 57/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.7892e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.6522e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 60/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.8797e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 62/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0015   \n",
      "Epoch 63/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.2270e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011    \n",
      "Epoch 65/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0014   \n",
      "Epoch 66/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.1609e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0047   \n",
      "Epoch 68/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012    \n",
      "Epoch 69/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0018   \n",
      "Epoch 70/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 71/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9948e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.3475e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.9800e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.2408e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6477e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8009e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.6924e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.2841e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.7053e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.4652e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.8756e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.5808e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.2940e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0099\n",
      "Epoch 85/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9731 - loss: 0.1316\n",
      "Epoch 86/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0165\n",
      "Epoch 87/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 88/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 89/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 90/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 91/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 92/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 93/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0014   \n",
      "Epoch 94/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012    \n",
      "Epoch 95/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0997e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.5686e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 98/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.6818e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 100/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.7717e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.5460e-04\n",
      "Epoch 102/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.9225e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012 \n",
      "Epoch 104/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.2809e-04\n",
      "Epoch 105/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.5472e-04\n",
      "Epoch 106/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.1390e-04\n",
      "Epoch 107/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.3585e-04\n",
      "Epoch 108/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.8107e-04\n",
      "Epoch 109/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.5551e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.5399e-04\n",
      "Epoch 111/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.2229e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8155e-04 \n",
      "Epoch 113/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.7951e-04 \n",
      "Epoch 114/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8927e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.7134e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8137e-04\n",
      "Epoch 117/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 118/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0650e-04\n",
      "Epoch 119/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.5936e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3422e-04\n",
      "Epoch 121/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5225e-04\n",
      "Epoch 122/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.9304e-04\n",
      "Epoch 123/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2489e-04\n",
      "Epoch 124/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.1793e-04\n",
      "Epoch 125/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.6638e-04\n",
      "Epoch 126/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0267e-04\n",
      "Epoch 127/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1424e-04\n",
      "Epoch 128/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3831e-04\n",
      "Epoch 129/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4772e-04\n",
      "Epoch 130/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.8503e-04\n",
      "Epoch 131/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.2242e-04\n",
      "Epoch 132/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3164e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.7663e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.4867e-04\n",
      "Epoch 135/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.2071e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2501e-04\n",
      "Epoch 137/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.6137e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9545e-04 \n",
      "Epoch 139/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3761e-04 \n",
      "Epoch 140/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5206e-04 \n",
      "Epoch 141/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3028e-04\n",
      "Epoch 142/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0908e-04 \n",
      "Epoch 143/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.5182e-04\n",
      "Epoch 144/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8832e-04\n",
      "Epoch 145/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0531e-04 \n",
      "Epoch 146/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1663e-04 \n",
      "Epoch 147/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7402e-04 \n",
      "Epoch 148/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.4026e-05 \n",
      "Epoch 149/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7867e-04 \n",
      "Epoch 150/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.5255e-04 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4772 - loss: 1.2965\n",
      "Epoch 2/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6678 - loss: 0.8122\n",
      "Epoch 3/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8699 - loss: 0.4424\n",
      "Epoch 4/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9230 - loss: 0.2807 \n",
      "Epoch 5/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.1568 \n",
      "Epoch 6/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9731 - loss: 0.1066 \n",
      "Epoch 7/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0913 \n",
      "Epoch 8/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0722 \n",
      "Epoch 9/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0544 \n",
      "Epoch 10/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0456 \n",
      "Epoch 11/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0303 \n",
      "Epoch 12/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0398 \n",
      "Epoch 13/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9934 - loss: 0.0267 \n",
      "Epoch 14/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0301\n",
      "Epoch 15/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0305\n",
      "Epoch 16/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0188 \n",
      "Epoch 17/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0141 \n",
      "Epoch 18/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0087 \n",
      "Epoch 19/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0091 \n",
      "Epoch 20/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0111 \n",
      "Epoch 21/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 22/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0147\n",
      "Epoch 23/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 24/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0073\n",
      "Epoch 25/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 26/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0055 \n",
      "Epoch 27/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 28/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0075 \n",
      "Epoch 29/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0088 \n",
      "Epoch 30/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 31/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 32/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 33/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0074 \n",
      "Epoch 34/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0074\n",
      "Epoch 35/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0024     \n",
      "Epoch 36/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 37/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0068 \n",
      "Epoch 38/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 39/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0068 \n",
      "Epoch 40/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 41/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 42/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 43/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0045\n",
      "Epoch 44/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0098 \n",
      "Epoch 45/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0053 \n",
      "Epoch 46/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 47/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 48/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 49/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 50/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0026\n",
      "Epoch 51/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 52/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 53/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 54/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 55/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 56/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 57/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 58/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0014     \n",
      "Epoch 59/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 60/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 61/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016  \n",
      "Epoch 62/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.9635e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 64/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.2227e-04 \n",
      "Epoch 65/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0010\n",
      "Epoch 66/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.8849e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 68/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0010    \n",
      "Epoch 69/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011  \n",
      "Epoch 70/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0053\n",
      "Epoch 71/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0038     \n",
      "Epoch 72/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 73/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 74/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0036     \n",
      "Epoch 75/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 76/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1772e-04 \n",
      "Epoch 77/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 78/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0022     \n",
      "Epoch 79/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 80/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.5628e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.4190e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0057e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0882e-04 \n",
      "Epoch 84/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016     \n",
      "Epoch 85/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 86/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0035     \n",
      "Epoch 87/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 88/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0862e-04 \n",
      "Epoch 89/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 90/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.6321e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.5455e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 93/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.0991e-04 \n",
      "Epoch 94/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4325e-04 \n",
      "Epoch 95/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1277e-04 \n",
      "Epoch 96/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1273e-04 \n",
      "Epoch 97/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7842e-04 \n",
      "Epoch 98/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.3177e-04 \n",
      "Epoch 99/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.3784e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5809e-04  \n",
      "Epoch 101/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8311e-04 \n",
      "Epoch 102/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6625e-04\n",
      "Epoch 103/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9704e-04 \n",
      "Epoch 104/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4491e-04 \n",
      "Epoch 105/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5727e-04 \n",
      "Epoch 106/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7952e-04 \n",
      "Epoch 107/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8054e-04 \n",
      "Epoch 108/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8224e-04 \n",
      "Epoch 109/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.1461e-04\n",
      "Epoch 110/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0324e-04 \n",
      "Epoch 111/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.5293e-04\n",
      "Epoch 112/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6513e-04\n",
      "Epoch 113/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.5047e-04 \n",
      "Epoch 114/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5031e-04\n",
      "Epoch 115/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.4694e-04\n",
      "Epoch 116/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2323e-04 \n",
      "Epoch 117/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2801e-04 \n",
      "Epoch 118/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4362e-04 \n",
      "Epoch 119/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.1255e-04\n",
      "Epoch 120/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6851e-04 \n",
      "Epoch 121/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5122e-04 \n",
      "Epoch 122/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 123/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0254 \n",
      "Epoch 124/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.0680 \n",
      "Epoch 125/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0182 \n",
      "Epoch 126/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 127/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 128/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0022\n",
      "Epoch 129/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019   \n",
      "Epoch 130/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 131/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 132/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.0415e-04\n",
      "Epoch 133/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.0570e-04\n",
      "Epoch 134/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 135/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.1907e-04\n",
      "Epoch 136/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 137/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.0010e-04\n",
      "Epoch 138/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3041e-04 \n",
      "Epoch 139/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7878e-04 \n",
      "Epoch 140/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 141/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.7270e-04\n",
      "Epoch 142/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6579e-04 \n",
      "Epoch 143/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6863e-04 \n",
      "Epoch 144/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 145/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.2750e-04 \n",
      "Epoch 146/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.1135e-04\n",
      "Epoch 147/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1198e-04\n",
      "Epoch 148/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.0947e-04\n",
      "Epoch 149/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6415e-04\n",
      "Epoch 150/150\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.0595e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "#cross val with grid cv\n",
    "\n",
    "'''\n",
    "random_cv_model = random_model.best_estimator_\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(random_cv_model, X_cv, np.argmax(y_test, axis=1), cv=kfold,scoring= 'accuracy')\n",
    "\n",
    "'''\n",
    "cv_model = grid_cv_model.best_estimator_\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "#np.argmax(y_test, axis=1)\n",
    "results = cross_val_score(cv_model, X,y, cv=kfold,scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7c5ad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Cross Validation Accuracy Results:  [0.96638655 0.99159664 0.99159664 1.         0.98319328]\n",
      "K-fold Cross Validation Accuracy Results Mean:  0.9865546218487395\n"
     ]
    }
   ],
   "source": [
    "#print kfold results\n",
    "print('K-fold Cross Validation Accuracy Results: ', results)\n",
    "print('K-fold Cross Validation Accuracy Results Mean: ', results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aef10a50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 32x32; Received: input_shape=(16, 16, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#evaluating acc of resNet50 model compaired to our model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m resNet50Model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m resNet50Model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m     16\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\keras\\src\\applications\\resnet.py:406\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    403\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack_residual_blocks_v1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack_residual_blocks_v1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\keras\\src\\applications\\resnet.py:125\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using `weights=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` with `include_top=True`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`classes` should be 1000.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived classes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m     )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[43mimagenet_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobtain_input_shape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_flatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     img_input \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_shape)\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\keras\\src\\applications\\imagenet_utils.py:390\u001b[0m, in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input must have 3 channels; Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`input_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m                 )\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    388\u001b[0m                 input_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m min_size\n\u001b[0;32m    389\u001b[0m             ) \u001b[38;5;129;01mor\u001b[39;00m (input_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m min_size):\n\u001b[1;32m--> 390\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    391\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput size must be at least \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    393\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    394\u001b[0m                 )\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m require_flatten:\n",
      "\u001b[1;31mValueError\u001b[0m: Input size must be at least 32x32; Received: input_shape=(16, 16, 3)"
     ]
    }
   ],
   "source": [
    "#evaluating acc of resNet50 model compaired to our model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "resNet50Model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(16, 16, 3),\n",
    "    pooling=None,\n",
    "    classes=5,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "for layer in resNet50Model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "dnn_model = keras.models.Sequential()\n",
    "dnn_model.add(resNet50Model)\n",
    "dnn_model.add(keras.layers.Flatten())\n",
    "dnn_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "dnn_model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "dnn_model.summary()\n",
    "dnn_model.compile(optimizer=keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "resnetHistory = dnn_model.fit(X_train, validation_data = X_test, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979246b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
