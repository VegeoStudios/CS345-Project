{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee19a590",
   "metadata": {},
   "source": [
    "-[Cross validation using grid search](https://www.kaggle.com/code/muhammetvarl/keras-multiclass-classification-cross-validation)\n",
    "\n",
    "-[resnet50Docs](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93ff7b10-6629-4374-9399-e2df4a0cb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import scipy.signal\n",
    "import keras\n",
    "import ipywidgets as widgets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "219b7d07-c5d3-4624-85ad-22391975a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89400, 5)\n",
      "(89400, 16, 16, 3)\n",
      "(595, 5)\n",
      "(595, 16, 16, 3)\n",
      "[[[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 99  27  79]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 76  20  55]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 76  20  55]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 97  65  41]\n",
      "   ...\n",
      "   [ 97  65  41]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 73  49  31]\n",
      "   ...\n",
      "   [ 73  49  31]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 73  49  31]\n",
      "   ...\n",
      "   [ 73  49  31]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 209  69]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 209  69]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 37  37  37]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [230  34  34]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [230  34  34]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 37  37  37]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [136  95  51]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 13  13  13]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.load('./Dataset1/sprites_labels.npy')\n",
    "sprites = np.load('./Dataset1/sprites.npy')\n",
    "\n",
    "print(data.shape)\n",
    "print(sprites.shape)\n",
    "\n",
    "selected_data = data[:894]\n",
    "selected_data = np.delete(selected_data, slice(244, 543), axis=0) #deletes duplicates\n",
    "print(selected_data.shape)\n",
    "\n",
    "selected_sprites = sprites[:894]\n",
    "selected_sprites = np.delete(selected_sprites, slice(244, 543), axis=0) #deletes duplicates\n",
    "print(selected_sprites.shape)\n",
    "\n",
    "data_with_mirrored = np.concatenate((selected_data, selected_data), axis=0)\n",
    "\n",
    "mirrored_sprites = np.flip(selected_sprites, axis=2)\n",
    "sprites_with_mirrored = np.concatenate((selected_sprites, mirrored_sprites), axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(selected_sprites[1])\n",
    "ax[1].imshow(mirrored_sprites[1]);\n",
    "\n",
    "print(sprites_with_mirrored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03821100-10bd-4767-bebd-f04bfb5d37e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sprites_with_mirrored, data_with_mirrored)\n",
    "\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, 5)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, 5)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "\n",
    "conv_result = scipy.signal.convolve2d(X_train[400, :, :, :1].reshape(16, 16), np.array([[1,2,1],[0,0,0],[-1,-2,-1]]).T)\n",
    "im = ax.imshow(conv_result, cmap='Greys')\n",
    "ax2.imshow(X_train[400, :, :, :1])\n",
    "ax.axis('off')\n",
    "fig.colorbar(im, ax=[ax, ax2]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17bf0d9f-481e-4ec2-b77a-9a0c06d5efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "conv_network = tf.keras.Sequential()\n",
    "\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Flatten())\n",
    "\n",
    "conv_network.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "conv_network.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data1 = np.load('./Dataset1/sprites_labels.npy')\n",
    "sprites1 = np.load('./Dataset1/sprites.npy')\n",
    "\n",
    "selected_labels = data1[:894]\n",
    "y = np.delete(selected_labels, slice(244, 543), axis=0)\n",
    "\n",
    "selected_sprites = sprites1[:894]\n",
    "X = np.delete(selected_sprites, slice(244, 543), axis=0)\n",
    "\n",
    "X = X.astype(np.float32) / 255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b004bea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,3)),\n",
    "    #keras.layers.Conv2D(196, (3, 3), strides=(1,1), activation='relu', input_shape=(16,16,3)),\n",
    "    keras.layers.Flatten(input_shape=(16, 16, 3)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "]);\n",
    "\n",
    "#other activations functions tried include sigmoid and different orders of relu and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52014fd3-cadd-45b2-805c-dd325ee47c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.8032144e-19 1.0000000e+00 0.0000000e+00 3.6022981e-12 4.1474057e-20]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model(X_train[:1]).numpy()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "181fd53c-b0d8-43a9-80c5-21efb0b9377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14884758, 0.40460962, 0.14884758, 0.14884758, 0.14884758]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b37e5b09-a018-4b7b-a0a1-cc6736fe2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.CategoricalCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea37ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.118095"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cd1453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "loss_fn1 = keras.losses.CategoricalFocalCrossentropy()\n",
    "loss_fn1(y_train[:1], predictions).numpy()\n",
    "'''\n",
    "\n",
    "#loss_fn2 = keras.losses.SparseCategoricalCrossentropy()\n",
    "#loss_fn2(y_train[:2], predictions).numpy()\n",
    "\n",
    "model.compile(optimizer='Adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "#Tried with RMSProp, SGD, Adadelta. Adam appears to have the most acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce19adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3895 - loss: 38.3665 - val_accuracy: 0.7617 - val_loss: 2.0567\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6712 - loss: 3.2641 - val_accuracy: 0.8087 - val_loss: 1.1350\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7737 - loss: 1.0165 - val_accuracy: 0.8255 - val_loss: 0.3993\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8350 - loss: 0.4562 - val_accuracy: 0.8725 - val_loss: 0.3303\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8624 - loss: 0.3883 - val_accuracy: 0.9161 - val_loss: 0.2894\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8888 - loss: 0.3198 - val_accuracy: 0.9262 - val_loss: 0.2133\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2402 - val_accuracy: 0.9228 - val_loss: 0.1809\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9096 - loss: 0.2026 - val_accuracy: 0.9396 - val_loss: 0.1636\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.2055 - val_accuracy: 0.9564 - val_loss: 0.1503\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9365 - loss: 0.1423 - val_accuracy: 0.9597 - val_loss: 0.1322\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9503 - loss: 0.1479 - val_accuracy: 0.9698 - val_loss: 0.1246\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9392 - loss: 0.1245 - val_accuracy: 0.9698 - val_loss: 0.1142\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.1082 - val_accuracy: 0.9698 - val_loss: 0.1072\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9629 - loss: 0.0962 - val_accuracy: 0.9732 - val_loss: 0.0956\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9670 - loss: 0.0779 - val_accuracy: 0.9732 - val_loss: 0.0959\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9748 - loss: 0.0685 - val_accuracy: 0.9732 - val_loss: 0.1002\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9783 - loss: 0.0638 - val_accuracy: 0.9765 - val_loss: 0.0965\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0684 - val_accuracy: 0.9765 - val_loss: 0.0854\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9643 - loss: 0.0860 - val_accuracy: 0.9732 - val_loss: 0.1325\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0614 - val_accuracy: 0.9765 - val_loss: 0.0868\n"
     ]
    }
   ],
   "source": [
    "historyConv = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "186cff56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2401</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">153,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m49\u001b[0m)       │         \u001b[38;5;34m1,372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2401\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m153,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466,277</span> (1.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m466,277\u001b[0m (1.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">155,425</span> (607.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m155,425\u001b[0m (607.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,852</span> (1.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m310,852\u001b[0m (1.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0854e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85, 1.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historyConv.history['accuracy'], label='Train')\n",
    "plt.plot(historyConv.history['val_accuracy'], label='test')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1af06fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - 2ms/step - accuracy: 0.9765 - loss: 0.0868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08682893216609955, 0.9765100479125977]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "867e603c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758],\n",
       "       [0.14884761, 0.14884761, 0.14884761, 0.1488477 , 0.40460947],\n",
       "       [0.14885317, 0.14885317, 0.14885317, 0.14887498, 0.40456548],\n",
       "       [0.1488733 , 0.14887598, 0.4044061 , 0.14897126, 0.1488733 ],\n",
       "       [0.1488513 , 0.1488513 , 0.14886585, 0.4045802 , 0.1488513 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model = keras.Sequential([model, keras.layers.Softmax()])\n",
    "probability_model(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4b46914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3504c07104804763a26eab35250ada56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Image index:', max=297), Output()), _dom_classes=('widge…"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "label_names = ['Character (FORWARD)', 'Monster', 'Food', 'Item', 'Character (SIDE)']\n",
    "index_slider = widgets.IntSlider(value=0, min=0, max=len(X_test)-1, description='Image index:')\n",
    "def show_image(index):\n",
    "    plt.imshow(X_test[index])\n",
    "    plt.show()\n",
    "    prediction = probability_model(X_test[index:index+1]).numpy()\n",
    "    print(f'Predicted label: {np.argmax(prediction)} ({label_names[np.argmax(prediction)]})')\n",
    "    print(f'Actual label: {np.argmax(y_test[index])} ({label_names[np.argmax(y_test[index])]})')\n",
    "    print('Predicted probabilities:')\n",
    "    print(f'    Character (FORWARD): {'%.2f' % (prediction[0][0] * 100)}%')\n",
    "    print(f'    Monster:             {'%.2f' % (prediction[0][1] * 100)}%')\n",
    "    print(f'    Food:                {'%.2f' % (prediction[0][2] * 100)}%')\n",
    "    print(f'    Item:                {'%.2f' % (prediction[0][3] * 100)}%')\n",
    "    print(f'    Character (SIDE):    {'%.2f' % (prediction[0][4] * 100)}%')\n",
    "widgets.interactive(show_image, index=index_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa7f7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter add_conv_layer for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(add_conv_layer=True)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 883, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1175, in set_params\n    raise ValueError(\nValueError: Invalid parameter add_conv_layer for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(add_conv_layer=True)`\nCheck the list of available parameters with `estimator.get_params().keys()`\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 102\u001b[0m\n\u001b[0;32m     94\u001b[0m model_cv \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mcreate_model, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     96\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel_cv,  \n\u001b[0;32m     97\u001b[0m                     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m     98\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     99\u001b[0m                     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m    100\u001b[0m                     param_grid\u001b[38;5;241m=\u001b[39mparam_grid)\n\u001b[1;32m--> 102\u001b[0m grid_cv_model \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m grid_cv_model\u001b[38;5;241m.\u001b[39mpredict(X_validate)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(y_validate \u001b[38;5;241m==\u001b[39m y_pred))\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter add_conv_layer for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(add_conv_layer=True)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def create_model(optimizer='adam', add_conv_layer=True, lossFunction='MSE'):\n",
    "    model = keras.models.Sequential()\n",
    "    if(add_conv_layer):\n",
    "        #model.add(keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,3)))\n",
    "        model.add(keras.layers.Conv2D(256, (3, 3), strides=(1,1), activation='relu', input_shape=(16,16,3)))\n",
    "        model.add(keras.layers.Flatten(input_shape=(16, 16, 3)))\n",
    "        model.add(keras.layers.Dense(64, activation='relu'))\n",
    "        model.add(keras.layers.Dropout(0.2))\n",
    "        model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    \n",
    "    model.compile(loss= lossFunction, optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "'''\n",
    "resNet50Model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(16, 16, 3),\n",
    "    pooling=None,\n",
    "    classes=5,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "for layer in resNet50Model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "dnn_model = keras.models.Sequential()\n",
    "dnn_model.add(resNet50Model)\n",
    "dnn_model.add(keras.layers.Flatten())\n",
    "dnn_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "dnn_model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "'''\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.2, random_state=43, shuffle=True)\n",
    "\n",
    "'''\n",
    "param_grid = {\n",
    "    'epochs' : [50, 100, 150],\n",
    "    'batch_size' : [32, 50, 100],\n",
    "    'optimizer' : ['Adam', 'Adadelta', 'SGD']\n",
    "}\n",
    "\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_cv, param_distributions=param_grid, n_iter=15\n",
    ")\n",
    "\n",
    "random_model = random_search.fit(X,y)\n",
    "\n",
    "start = time()\n",
    "print(\n",
    "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
    "    % ((time() - start), 15)\n",
    ")\n",
    "report(random_search.cv_results_)\n",
    "'''\n",
    "\n",
    "'''\n",
    " 'epochs' : [50, 100, 150],\n",
    "'batch_size' : [32, 50, 100],\n",
    "'''\n",
    "param_grid = {\n",
    "    'epochs' : [50, 150],\n",
    "    'batch_size' : [32, 100],\n",
    "    'optimizer' : ['Adam', 'Adadelta', 'SGD'],\n",
    "    'add_conv_layer' : [True, False],\n",
    "    'loss' : ['MSE', 'categorical_crossentropy', 'sparse_categorical_crossentropy']\n",
    "}\n",
    "\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=1, optimizer='adam', add_conv_layer=True, lossFunction='MSE')\n",
    "\n",
    "grid = GridSearchCV(estimator=model_cv,  \n",
    "                    n_jobs=-1, \n",
    "                    verbose=1,\n",
    "                    cv=5,\n",
    "                    param_grid=param_grid)\n",
    "\n",
    "grid_cv_model = grid.fit(X_train, y_train,)\n",
    "\n",
    "y_pred = grid_cv_model.predict(X_validate)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \", np.mean(y_validate == y_pred))\n",
    "\n",
    "means = grid_cv_model.cv_results_['mean_test_score'] # Mean of test scores\n",
    "stds = grid_cv_model.cv_results_['std_test_score'] # standard deviations of test scores\n",
    "params = grid_cv_model.cv_results_['params'] # parameters used\n",
    "# to print all scores, standard deviations and parameters used\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Printing the Best Parameters as a Result of Grid Search Cross Validation on the Screen\n",
    "print(\"Best: %f using %s\" % (grid_cv_model.best_score_, grid_cv_model.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb99aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5098 - loss: 1.2675  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7550 - loss: 0.6372 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.3126 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.2032 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1622 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1256 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9720 - loss: 0.1006 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9876 - loss: 0.0616 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9767 - loss: 0.0758 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0447 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9976 - loss: 0.0272 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0213 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9921 - loss: 0.0308 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9933 - loss: 0.0277 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0192 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0113 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0125 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0111 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0069 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0087 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0066 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0059 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037     \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0067 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0058 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0057 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0075 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029     \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0086     \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0054 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5227 - loss: 1.2328  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7146 - loss: 0.7835 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8540 - loss: 0.4368 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2683 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1738 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9852 - loss: 0.1081 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9766 - loss: 0.1054 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9786 - loss: 0.0846 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9820 - loss: 0.0649 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0417 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0316 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0357 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0317 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9919 - loss: 0.0422 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0246 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0196 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0213 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0237 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0139 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0121 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0089 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0106 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0152 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0149 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0083 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0095 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0071 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0085 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0043 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0047 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030     \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031     \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0051     \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000203C561C720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4791 - loss: 1.3185  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8191 - loss: 0.5854 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9284 - loss: 0.2670 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1386 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.1051 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0568 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0412 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9893 - loss: 0.0387 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9923 - loss: 0.0406 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0207 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0143 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0109 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0148 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0160 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0116 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0115 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0091 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0131 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0107 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0060 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0063 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0101 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.7584e-04 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0025     \n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000203C54DAAC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5128 - loss: 1.3246  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7493 - loss: 0.7105 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.3709 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.2083 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9657 - loss: 0.1636 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9633 - loss: 0.1306 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9862 - loss: 0.0805 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9951 - loss: 0.0601 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9893 - loss: 0.0697 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0354 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0361 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0269 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9921 - loss: 0.0311 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0217 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0152 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0149 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0212 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0232 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0186 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0111 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0099 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0065 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0079 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0044 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0066 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0046 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0041 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020     \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5752 - loss: 1.2388  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7487 - loss: 0.6823 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8957 - loss: 0.3453 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1907 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9752 - loss: 0.1168 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0764 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.0785 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0404 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0389 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0336 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0272 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0280 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0225 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0203 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0252 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0136 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0107 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0157 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0091 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0114 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0080 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0085 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0127 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0093 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0140 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0034     \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "#cross val with grid cv\n",
    "\n",
    "'''\n",
    "random_cv_model = random_model.best_estimator_\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(random_cv_model, X_cv, np.argmax(y_test, axis=1), cv=kfold,scoring= 'accuracy')\n",
    "\n",
    "'''\n",
    "cv_model = grid_cv_model.best_estimator_\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "results = cross_val_score(cv_model, X,y, cv=kfold,scoring= 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5ad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Cross Validation Accuracy Results:  [0.98319328 0.99159664 0.99159664 0.97478992 0.98319328]\n",
      "K-fold Cross Validation Accuracy Results Mean:  0.984873949579832\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "X_train shape:  (380, 16, 16, 3)\n",
      "y_test shape: (119, 5)\n",
      "y_validate shape: (96, 5)\n",
      "y_pred shape: (380, 5)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6740 - loss: 1.0968  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7086 - loss: 0.7270 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8311 - loss: 0.4107 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2415 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9826 - loss: 0.1391 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0993 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0594 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0506 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0399 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0332 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0252 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0170 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0145 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0159 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0109 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0108 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0101 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0102 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0084 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0077 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0072 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0060 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0112 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0105 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020     \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0046 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027     \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017     \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6050 - loss: 1.0559  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.4478 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2835 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9816 - loss: 0.1254 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9865 - loss: 0.0915 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9832 - loss: 0.0755 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.0741 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9873 - loss: 0.0485 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9918 - loss: 0.0363 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9901 - loss: 0.0352 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0268 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0157 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0197 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0147 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0088 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0067 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0094 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0058 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0151 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0063 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032     \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029     \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0172     \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0068 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0089 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017     \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012     \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0024     \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0060 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0054 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0033 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6154e-04 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4214 - loss: 1.3886   \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6421 - loss: 0.9070 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.4287 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.3010 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9575 - loss: 0.1775 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9793 - loss: 0.1136 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9836 - loss: 0.0982 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0638 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0447 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0524 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9860 - loss: 0.0489 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0363 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0206 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0307 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0294 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0148 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0142 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0174 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0135 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0096 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0139 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0087 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0104 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0066 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0057 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0045 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0046 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037     \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4232 - loss: 1.4141   \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.7834 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.4485 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.2297 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1479 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.1206 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9876 - loss: 0.0790 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0701 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0429 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0377 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0248 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0280 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0222 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0177 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0125 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0157 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0168 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0112 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0126 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0109 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0101 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0068 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0090 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0098 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0074 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048     \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0055 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4682 - loss: 1.3844  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.8660 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8862 - loss: 0.4685 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.3041 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.1817 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.1423 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.1227 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0767 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9844 - loss: 0.0816 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0601 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0524 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0368 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0362 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0261 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0188 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0168 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0166 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0278 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0128 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0189 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0183 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0136 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0076 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0124 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0088 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0080 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0081 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0132 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0139 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0045 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Evaluate on test set:  0.8184873949579833\n"
     ]
    }
   ],
   "source": [
    "#print kfold results\n",
    "print('K-fold Cross Validation Accuracy Results: ', results)\n",
    "print('K-fold Cross Validation Accuracy Results Mean: ', results.mean())\n",
    "\n",
    "\n",
    "y_pred = cv_model.predict(X_train)\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"y_validate shape:\", y_validate.shape)\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "y_test_int = y_test.astype(int) #make sure y_test and y_pred are compatible\n",
    "test_acc = cross_val_score(cv_model, X, y, scoring = 'accuracy')\n",
    "print('Evaluate on test set: ', np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef10a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#evaluating acc of resNet50 model compaired to our model\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\\n\\nresNet50Model = tf.keras.applications.ResNet50(\\n    include_top=False,\\n    weights='imagenet',\\n    input_tensor=None,\\n    input_shape=(16, 16, 3),\\n    pooling=None,\\n    classes=5,\\n    classifier_activation='softmax'\\n)\\n\\nfor layer in resNet50Model.layers:\\n    layer.trainable=False\\n    \\ndnn_model = keras.models.Sequential()\\ndnn_model.add(resNet50Model)\\ndnn_model.add(keras.layers.Flatten())\\ndnn_model.add(keras.layers.Dense(512, activation='relu'))\\ndnn_model.add(keras.layers.Dense(5, activation='softmax'))\\n\\ndnn_model.summary()\\ndnn_model.compile(optimizer=keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\\n\\n\\nresnetHistory = dnn_model.fit(X_train, validation_data = X_test, epochs = 20)\\n\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "#evaluating acc of resNet50 model compaired to our model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "resNet50Model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(16, 16, 3),\n",
    "    pooling=None,\n",
    "    classes=5,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "for layer in resNet50Model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "dnn_model = keras.models.Sequential()\n",
    "dnn_model.add(resNet50Model)\n",
    "dnn_model.add(keras.layers.Flatten())\n",
    "dnn_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "dnn_model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "dnn_model.summary()\n",
    "dnn_model.compile(optimizer=keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "resnetHistory = dnn_model.fit(X_train, validation_data = X_test, epochs = 20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979246b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
