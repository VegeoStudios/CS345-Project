{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee19a590",
   "metadata": {},
   "source": [
    "-[Cross validation using grid search](https://www.kaggle.com/code/muhammetvarl/keras-multiclass-classification-cross-validation)\n",
    "\n",
    "-[resnet50Docs](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93ff7b10-6629-4374-9399-e2df4a0cb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import scipy.signal\n",
    "import keras\n",
    "import ipywidgets as widgets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "219b7d07-c5d3-4624-85ad-22391975a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89400, 5)\n",
      "(89400, 16, 16, 3)\n",
      "(595, 5)\n",
      "(595, 16, 16, 3)\n",
      "[[[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 99  27  79]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 76  20  55]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 76  20  55]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 97  65  41]\n",
      "   ...\n",
      "   [ 97  65  41]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 73  49  31]\n",
      "   ...\n",
      "   [ 73  49  31]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 73  49  31]\n",
      "   ...\n",
      "   [ 73  49  31]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 209  69]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 209  69]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 37  37  37]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [230  34  34]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [230  34  34]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 37  37  37]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [136  95  51]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 13  13  13]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.load('./Dataset1/sprites_labels.npy')\n",
    "sprites = np.load('./Dataset1/sprites.npy')\n",
    "\n",
    "print(data.shape)\n",
    "print(sprites.shape)\n",
    "\n",
    "selected_data = data[:894]\n",
    "selected_data = np.delete(selected_data, slice(244, 543), axis=0) #deletes duplicates\n",
    "print(selected_data.shape)\n",
    "\n",
    "selected_sprites = sprites[:894]\n",
    "selected_sprites = np.delete(selected_sprites, slice(244, 543), axis=0) #deletes duplicates\n",
    "print(selected_sprites.shape)\n",
    "\n",
    "data_with_mirrored = np.concatenate((selected_data, selected_data), axis=0)\n",
    "\n",
    "mirrored_sprites = np.flip(selected_sprites, axis=2)\n",
    "sprites_with_mirrored = np.concatenate((selected_sprites, mirrored_sprites), axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(selected_sprites[1])\n",
    "ax[1].imshow(mirrored_sprites[1]);\n",
    "\n",
    "print(sprites_with_mirrored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03821100-10bd-4767-bebd-f04bfb5d37e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sprites_with_mirrored, data_with_mirrored)\n",
    "\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, 5)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, 5)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "\n",
    "conv_result = scipy.signal.convolve2d(X_train[400, :, :, :1].reshape(16, 16), np.array([[1,2,1],[0,0,0],[-1,-2,-1]]).T)\n",
    "im = ax.imshow(conv_result, cmap='Greys')\n",
    "ax2.imshow(X_train[400, :, :, :1])\n",
    "ax.axis('off')\n",
    "fig.colorbar(im, ax=[ax, ax2]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17bf0d9f-481e-4ec2-b77a-9a0c06d5efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "conv_network = tf.keras.Sequential()\n",
    "\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Flatten())\n",
    "\n",
    "conv_network.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "conv_network.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data1 = np.load('./Dataset1/sprites_labels.npy')\n",
    "sprites1 = np.load('./Dataset1/sprites.npy')\n",
    "\n",
    "selected_labels = data1[:894]\n",
    "y = np.delete(selected_labels, slice(244, 543), axis=0)\n",
    "\n",
    "selected_sprites = sprites1[:894]\n",
    "X = np.delete(selected_sprites, slice(244, 543), axis=0)\n",
    "\n",
    "X = X.astype(np.float32) / 255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b004bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,3)),\n",
    "    #keras.layers.Conv2D(196, (3, 3), strides=(1,1), activation='relu', input_shape=(16,16,3)),\n",
    "    keras.layers.Flatten(input_shape=(16, 16, 3)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "]);\n",
    "\n",
    "#other activations functions tried include sigmoid and different orders of relu and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52014fd3-cadd-45b2-805c-dd325ee47c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000000e+00 5.395378e-07 9.999994e-01 8.999007e-19 0.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model(X_train[:1]).numpy()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "181fd53c-b0d8-43a9-80c5-21efb0b9377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14884761, 0.14884768, 0.40460947, 0.14884761, 0.14884761]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b37e5b09-a018-4b7b-a0a1-cc6736fe2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.CategoricalCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ea37ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.118095"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3cd1453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "loss_fn1 = keras.losses.CategoricalFocalCrossentropy()\n",
    "loss_fn1(y_train[:1], predictions).numpy()\n",
    "'''\n",
    "\n",
    "#loss_fn2 = keras.losses.SparseCategoricalCrossentropy()\n",
    "#loss_fn2(y_train[:2], predictions).numpy()\n",
    "\n",
    "model.compile(optimizer='Adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "#Tried with RMSProp, SGD, Adadelta. Adam appears to have the most acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ce19adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 291ms/step - accuracy: 0.4168 - loss: 48.7069 - val_accuracy: 0.6644 - val_loss: 4.1809\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.5365 - loss: 2.5417 - val_accuracy: 0.5973 - val_loss: 1.3531\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.5597 - loss: 1.4236 - val_accuracy: 0.6242 - val_loss: 1.2089\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5633 - loss: 1.2351 - val_accuracy: 0.6275 - val_loss: 0.9088\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5972 - loss: 1.0953 - val_accuracy: 0.6275 - val_loss: 0.8769\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.5888 - loss: 1.0012 - val_accuracy: 0.6275 - val_loss: 0.8054\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5853 - loss: 0.9812 - val_accuracy: 0.6275 - val_loss: 0.8228\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.5718 - loss: 0.9276 - val_accuracy: 0.6275 - val_loss: 0.7458\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5737 - loss: 0.9214 - val_accuracy: 0.6275 - val_loss: 0.7126\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5853 - loss: 0.8311 - val_accuracy: 0.7450 - val_loss: 0.6908\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6391 - loss: 0.8184 - val_accuracy: 0.7483 - val_loss: 0.6737\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6590 - loss: 0.7765 - val_accuracy: 0.7450 - val_loss: 0.6797\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6460 - loss: 0.7849 - val_accuracy: 0.7450 - val_loss: 0.6550\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7007 - loss: 0.7257 - val_accuracy: 0.7315 - val_loss: 0.6628\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6726 - loss: 0.7607 - val_accuracy: 0.7517 - val_loss: 0.6251\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6579 - loss: 0.7620 - val_accuracy: 0.7483 - val_loss: 0.6344\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6721 - loss: 0.7359 - val_accuracy: 0.7550 - val_loss: 0.6252\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6958 - loss: 0.7005 - val_accuracy: 0.7584 - val_loss: 0.6210\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6966 - loss: 0.7189 - val_accuracy: 0.7383 - val_loss: 0.6323\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.6848 - loss: 0.6851 - val_accuracy: 0.7550 - val_loss: 0.5926\n"
     ]
    }
   ],
   "source": [
    "historyConv = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "186cff56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2401</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">153,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_36 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m49\u001b[0m)       │         \u001b[38;5;34m1,372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_36 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2401\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_72 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m153,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_73 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466,277</span> (1.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m466,277\u001b[0m (1.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">155,425</span> (607.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m155,425\u001b[0m (607.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,852</span> (1.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m310,852\u001b[0m (1.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0854e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85, 1.0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historyConv.history['accuracy'], label='Train')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0.85, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1af06fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - 78ms/step - accuracy: 0.7550 - loss: 0.5926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5925683379173279, 0.755033552646637]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "867e603c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0.2045696 , 0.19717829, 0.19965732, 0.2017703 , 0.19682442],\n",
       "       [0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758],\n",
       "       [0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758],\n",
       "       [0.14884862, 0.14885263, 0.14884862, 0.4046015 , 0.14884862],\n",
       "       [0.1488477 , 0.14884815, 0.1488477 , 0.4046087 , 0.1488477 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model = keras.Sequential([model, keras.layers.Softmax()])\n",
    "probability_model(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4b46914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f971184a454a86b37df4dd044d4730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Image index:', max=297), Output()), _dom_classes=('widge…"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "label_names = ['Character (FORWARD)', 'Monster', 'Food', 'Item', 'Character (SIDE)']\n",
    "index_slider = widgets.IntSlider(value=0, min=0, max=len(X_test)-1, description='Image index:')\n",
    "def show_image(index):\n",
    "    plt.imshow(X_test[index])\n",
    "    plt.show()\n",
    "    prediction = probability_model(X_test[index:index+1]).numpy()\n",
    "    print(f'Predicted label: {np.argmax(prediction)} ({label_names[np.argmax(prediction)]})')\n",
    "    print(f'Actual label: {np.argmax(y_test[index])} ({label_names[np.argmax(y_test[index])]})')\n",
    "    print('Predicted probabilities:')\n",
    "    print(f'    Character (FORWARD): {'%.2f' % (prediction[0][0] * 100)}%')\n",
    "    print(f'    Monster:             {'%.2f' % (prediction[0][1] * 100)}%')\n",
    "    print(f'    Food:                {'%.2f' % (prediction[0][2] * 100)}%')\n",
    "    print(f'    Item:                {'%.2f' % (prediction[0][3] * 100)}%')\n",
    "    print(f'    Character (SIDE):    {'%.2f' % (prediction[0][4] * 100)}%')\n",
    "widgets.interactive(show_image, index=index_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fa7f7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter add_conv_layer for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(add_conv_layer=True)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\cjbea\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"C:\\Users\\cjbea\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\cjbea\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\cjbea\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\cjbea\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 883, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1175, in set_params\n    raise ValueError(\nValueError: Invalid parameter add_conv_layer for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(add_conv_layer=True)`\nCheck the list of available parameters with `estimator.get_params().keys()`\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 96\u001b[0m\n\u001b[0;32m     88\u001b[0m model_cv \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mcreate_model, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     90\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel_cv,  \n\u001b[0;32m     91\u001b[0m                     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m     92\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     93\u001b[0m                     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     94\u001b[0m                     param_grid\u001b[38;5;241m=\u001b[39mparam_grid)\n\u001b[1;32m---> 96\u001b[0m grid_cv_model \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m grid_cv_model\u001b[38;5;241m.\u001b[39mpredict(X_validate)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(y_validate \u001b[38;5;241m==\u001b[39m y_pred))\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter add_conv_layer for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(add_conv_layer=True)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def create_model(optimizer, add_conv_layer, lossFunction):\n",
    "    model = keras.models.Sequential()\n",
    "    if(add_conv_layer):\n",
    "        model.add(keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,3)))\n",
    "        #model.add(keras.layers.Conv2D(256, (3, 3), strides=(1,1), activation='relu', input_shape=(16,16,3)))\n",
    "        model.add(keras.layers.Flatten(input_shape=(16, 16, 3)))\n",
    "        model.add(keras.layers.Dense(64, activation='relu'))\n",
    "        model.add(keras.layers.Dropout(0.2))\n",
    "        model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    \n",
    "    model.compile(loss= lossFunction, optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "'''\n",
    "resNet50Model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(16, 16, 3),\n",
    "    pooling=None,\n",
    "    classes=5,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "for layer in resNet50Model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "dnn_model = keras.models.Sequential()\n",
    "dnn_model.add(resNet50Model)\n",
    "dnn_model.add(keras.layers.Flatten())\n",
    "dnn_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "dnn_model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "'''\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.2, random_state=43, shuffle=True)\n",
    "\n",
    "'''\n",
    "param_grid = {\n",
    "    'epochs' : [50, 100, 150],\n",
    "    'batch_size' : [32, 50, 100],\n",
    "    'optimizer' : ['Adam', 'Adadelta', 'SGD']\n",
    "}\n",
    "\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_cv, param_distributions=param_grid, n_iter=15\n",
    ")\n",
    "\n",
    "random_model = random_search.fit(X,y)\n",
    "\n",
    "start = time()\n",
    "print(\n",
    "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
    "    % ((time() - start), 15)\n",
    ")\n",
    "report(random_search.cv_results_)\n",
    "'''\n",
    "\n",
    "'''\n",
    " 'epochs' : [50, 100, 150],\n",
    "'batch_size' : [32, 50, 100],\n",
    "'''\n",
    "param_grid = {\n",
    "    'epochs' : [50, 150],\n",
    "    'batch_size' : [32, 100],\n",
    "    'optimizer' : ['Adam', 'Adadelta', 'SGD'],\n",
    "    'add_conv_layer' : [True, False],\n",
    "    'loss' : ['MSE', 'categorical_crossentropy', 'sparse_categorical_crossentropy']\n",
    "}\n",
    "\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "grid = GridSearchCV(estimator=model_cv,  \n",
    "                    n_jobs=-1, \n",
    "                    verbose=1,\n",
    "                    cv=5,\n",
    "                    param_grid=param_grid)\n",
    "\n",
    "grid_cv_model = grid.fit(X_train, y_train,)\n",
    "\n",
    "y_pred = grid_cv_model.predict(X_validate)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \", np.mean(y_validate == y_pred))\n",
    "\n",
    "means = grid_cv_model.cv_results_['mean_test_score'] # Mean of test scores\n",
    "stds = grid_cv_model.cv_results_['std_test_score'] # standard deviations of test scores\n",
    "params = grid_cv_model.cv_results_['params'] # parameters used\n",
    "# to print all scores, standard deviations and parameters used\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Printing the Best Parameters as a Result of Grid Search Cross Validation on the Screen\n",
    "print(\"Best: %f using %s\" % (grid_cv_model.best_score_, grid_cv_model.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb99aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5098 - loss: 1.2675  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7550 - loss: 0.6372 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.3126 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.2032 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1622 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1256 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9720 - loss: 0.1006 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9876 - loss: 0.0616 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9767 - loss: 0.0758 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0447 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9976 - loss: 0.0272 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0213 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9921 - loss: 0.0308 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9933 - loss: 0.0277 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0192 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0113 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0125 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0111 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0069 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0087 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0066 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0059 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037     \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0067 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0058 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0057 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0075 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029     \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0086     \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0054 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5227 - loss: 1.2328  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7146 - loss: 0.7835 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8540 - loss: 0.4368 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2683 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1738 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9852 - loss: 0.1081 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9766 - loss: 0.1054 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9786 - loss: 0.0846 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9820 - loss: 0.0649 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0417 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0316 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0357 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0317 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9919 - loss: 0.0422 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0246 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0196 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0213 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0237 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0139 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0121 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0089 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0106 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0152 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0149 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0083 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0095 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0071 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0085 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0043 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0047 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030     \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031     \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0051     \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000203C561C720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4791 - loss: 1.3185  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8191 - loss: 0.5854 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9284 - loss: 0.2670 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1386 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.1051 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0568 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0412 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9893 - loss: 0.0387 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9923 - loss: 0.0406 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0207 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0143 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0109 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0148 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0160 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0116 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0115 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0091 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0131 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0107 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0060 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0063 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0101 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.7584e-04 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0025     \n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000203C54DAAC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5128 - loss: 1.3246  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7493 - loss: 0.7105 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.3709 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.2083 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9657 - loss: 0.1636 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9633 - loss: 0.1306 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9862 - loss: 0.0805 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9951 - loss: 0.0601 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9893 - loss: 0.0697 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0354 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0361 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0269 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9921 - loss: 0.0311 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0217 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0152 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0149 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0212 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0232 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0186 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0111 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0099 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0065 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0079 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0044 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0066 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0046 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0041 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020     \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5752 - loss: 1.2388  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7487 - loss: 0.6823 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8957 - loss: 0.3453 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1907 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9752 - loss: 0.1168 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0764 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.0785 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0404 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0389 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0336 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0272 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0280 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0225 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0203 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0252 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0136 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0107 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0157 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0091 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0114 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0080 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0085 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0127 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0093 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0140 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0034     \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "#cross val with grid cv\n",
    "\n",
    "'''\n",
    "random_cv_model = random_model.best_estimator_\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(random_cv_model, X_cv, np.argmax(y_test, axis=1), cv=kfold,scoring= 'accuracy')\n",
    "\n",
    "'''\n",
    "cv_model = grid_cv_model.best_estimator_\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "results = cross_val_score(cv_model, X,y, cv=kfold,scoring= 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5ad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Cross Validation Accuracy Results:  [0.98319328 0.99159664 0.99159664 0.97478992 0.98319328]\n",
      "K-fold Cross Validation Accuracy Results Mean:  0.984873949579832\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "X_train shape:  (380, 16, 16, 3)\n",
      "y_test shape: (119, 5)\n",
      "y_validate shape: (96, 5)\n",
      "y_pred shape: (380, 5)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6740 - loss: 1.0968  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7086 - loss: 0.7270 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8311 - loss: 0.4107 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2415 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9826 - loss: 0.1391 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0993 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0594 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0506 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0399 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0332 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0252 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0170 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0145 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0159 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0109 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0108 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0101 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0102 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0084 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0077 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0072 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0060 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0112 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0105 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020     \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0046 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027     \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017     \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6050 - loss: 1.0559  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.4478 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2835 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9816 - loss: 0.1254 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9865 - loss: 0.0915 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9832 - loss: 0.0755 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.0741 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9873 - loss: 0.0485 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9918 - loss: 0.0363 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9901 - loss: 0.0352 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0268 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0157 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0197 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0147 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0088 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0067 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0094 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0058 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0151 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0063 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032     \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029     \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0172     \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0068 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0089 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017     \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012     \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0024     \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0060 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0054 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0033 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6154e-04 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4214 - loss: 1.3886   \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6421 - loss: 0.9070 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.4287 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.3010 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9575 - loss: 0.1775 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9793 - loss: 0.1136 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9836 - loss: 0.0982 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0638 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0447 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0524 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9860 - loss: 0.0489 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0363 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0206 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0307 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0294 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0148 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0142 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0174 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0135 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0096 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0139 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0087 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0104 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0066 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0057 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0045 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0046 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037     \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4232 - loss: 1.4141   \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.7834 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.4485 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.2297 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1479 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.1206 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9876 - loss: 0.0790 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0701 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0429 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0377 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0248 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0280 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0222 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0177 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0125 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0157 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0168 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0112 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0126 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0109 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0101 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0068 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0090 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0098 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0074 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048     \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0055 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4682 - loss: 1.3844  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.8660 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8862 - loss: 0.4685 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.3041 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.1817 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.1423 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.1227 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0767 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9844 - loss: 0.0816 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0601 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0524 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0368 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0362 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0261 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0188 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0168 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0166 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0278 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0128 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0189 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0183 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0136 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0076 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0124 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0088 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0080 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0081 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0132 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0139 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0045 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Evaluate on test set:  0.8184873949579833\n"
     ]
    }
   ],
   "source": [
    "#print kfold results\n",
    "print('K-fold Cross Validation Accuracy Results: ', results)\n",
    "print('K-fold Cross Validation Accuracy Results Mean: ', results.mean())\n",
    "\n",
    "\n",
    "y_pred = cv_model.predict(X_train)\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"y_validate shape:\", y_validate.shape)\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "y_test_int = y_test.astype(int) #make sure y_test and y_pred are compatible\n",
    "test_acc = cross_val_score(cv_model, X, y, scoring = 'accuracy')\n",
    "print('Evaluate on test set: ', np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aef10a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#evaluating acc of resNet50 model compaired to our model\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\\n\\nresNet50Model = tf.keras.applications.ResNet50(\\n    include_top=False,\\n    weights='imagenet',\\n    input_tensor=None,\\n    input_shape=(16, 16, 3),\\n    pooling=None,\\n    classes=5,\\n    classifier_activation='softmax'\\n)\\n\\nfor layer in resNet50Model.layers:\\n    layer.trainable=False\\n    \\ndnn_model = keras.models.Sequential()\\ndnn_model.add(resNet50Model)\\ndnn_model.add(keras.layers.Flatten())\\ndnn_model.add(keras.layers.Dense(512, activation='relu'))\\ndnn_model.add(keras.layers.Dense(5, activation='softmax'))\\n\\ndnn_model.summary()\\ndnn_model.compile(optimizer=keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\\n\\n\\nresnetHistory = dnn_model.fit(X_train, validation_data = X_test, epochs = 20)\\n\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "#evaluating acc of resNet50 model compaired to our model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "resNet50Model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(16, 16, 3),\n",
    "    pooling=None,\n",
    "    classes=5,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "for layer in resNet50Model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "dnn_model = keras.models.Sequential()\n",
    "dnn_model.add(resNet50Model)\n",
    "dnn_model.add(keras.layers.Flatten())\n",
    "dnn_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "dnn_model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "dnn_model.summary()\n",
    "dnn_model.compile(optimizer=keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "resnetHistory = dnn_model.fit(X_train, validation_data = X_test, epochs = 20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979246b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
