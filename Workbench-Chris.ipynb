{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee19a590",
   "metadata": {},
   "source": [
    "-[Cross validation using grid search](https://www.kaggle.com/code/muhammetvarl/keras-multiclass-classification-cross-validation)\n",
    "\n",
    "-[resnet50Docs](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ff7b10-6629-4374-9399-e2df4a0cb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import scipy.signal\n",
    "import keras\n",
    "import ipywidgets as widgets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219b7d07-c5d3-4624-85ad-22391975a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89400, 5)\n",
      "(89400, 16, 16, 3)\n",
      "(595, 5)\n",
      "(595, 16, 16, 3)\n",
      "[[[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 99  27  79]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 76  20  55]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 76  20  55]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 97  65  41]\n",
      "   ...\n",
      "   [ 97  65  41]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 73  49  31]\n",
      "   ...\n",
      "   [ 73  49  31]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 73  49  31]\n",
      "   ...\n",
      "   [ 73  49  31]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 209  69]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 209  69]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 37  37  37]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [230  34  34]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [230  34  34]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 37  37  37]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [136  95  51]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 13  13  13]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.load('./Dataset1/sprites_labels.npy')\n",
    "sprites = np.load('./Dataset1/sprites.npy')\n",
    "\n",
    "print(data.shape)\n",
    "print(sprites.shape)\n",
    "\n",
    "selected_data = data[:894]\n",
    "selected_data = np.delete(selected_data, slice(244, 543), axis=0) #deletes duplicates\n",
    "print(selected_data.shape)\n",
    "\n",
    "selected_sprites = sprites[:894]\n",
    "selected_sprites = np.delete(selected_sprites, slice(244, 543), axis=0) #deletes duplicates\n",
    "print(selected_sprites.shape)\n",
    "\n",
    "data_with_mirrored = np.concatenate((selected_data, selected_data), axis=0)\n",
    "\n",
    "mirrored_sprites = np.flip(selected_sprites, axis=2)\n",
    "sprites_with_mirrored = np.concatenate((selected_sprites, mirrored_sprites), axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(selected_sprites[1])\n",
    "ax[1].imshow(mirrored_sprites[1]);\n",
    "\n",
    "print(sprites_with_mirrored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03821100-10bd-4767-bebd-f04bfb5d37e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sprites_with_mirrored, data_with_mirrored)\n",
    "\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, 5)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, 5)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "\n",
    "conv_result = scipy.signal.convolve2d(X_train[400, :, :, :1].reshape(16, 16), np.array([[1,2,1],[0,0,0],[-1,-2,-1]]).T)\n",
    "im = ax.imshow(conv_result, cmap='Greys')\n",
    "ax2.imshow(X_train[400, :, :, :1])\n",
    "ax.axis('off')\n",
    "fig.colorbar(im, ax=[ax, ax2]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bf0d9f-481e-4ec2-b77a-9a0c06d5efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "conv_network = tf.keras.Sequential()\n",
    "\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Flatten())\n",
    "\n",
    "conv_network.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "conv_network.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data1 = np.load('./Dataset1/sprites_labels.npy')\n",
    "sprites1 = np.load('./Dataset1/sprites.npy')\n",
    "\n",
    "selected_labels = data1[:894]\n",
    "y = np.delete(selected_labels, slice(244, 543), axis=0)\n",
    "\n",
    "selected_sprites = sprites1[:894]\n",
    "X = np.delete(selected_sprites, slice(244, 543), axis=0)\n",
    "\n",
    "X = X.astype(np.float32) / 255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b004bea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,3)),\n",
    "    #keras.layers.Conv2D(196, (3, 3), strides=(1,1), activation='relu', input_shape=(16,16,3)),\n",
    "    keras.layers.Flatten(input_shape=(16, 16, 3)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "]);\n",
    "\n",
    "#other activations functions tried include sigmoid and different orders of relu and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52014fd3-cadd-45b2-805c-dd325ee47c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.9256938e-33 5.6308085e-08 2.9749062e-06 9.9999702e-01 9.6787083e-31]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model(X_train[:1]).numpy()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181fd53c-b0d8-43a9-80c5-21efb0b9377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14884771, 0.14884771, 0.14884815, 0.4046088 , 0.14884771]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37e5b09-a018-4b7b-a0a1-cc6736fe2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.CategoricalCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea37ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.118095"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd1453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "loss_fn1 = keras.losses.CategoricalFocalCrossentropy()\n",
    "loss_fn1(y_train[:1], predictions).numpy()\n",
    "'''\n",
    "\n",
    "#loss_fn2 = keras.losses.SparseCategoricalCrossentropy()\n",
    "#loss_fn2(y_train[:2], predictions).numpy()\n",
    "\n",
    "model.compile(optimizer='Adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "#Tried with RMSProp, SGD, Adadelta. Adam appears to have the most acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce19adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.3809 - loss: 65.5764 - val_accuracy: 0.3926 - val_loss: 11.9011\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5608 - loss: 8.6059 - val_accuracy: 0.8557 - val_loss: 0.9224\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7751 - loss: 1.5369 - val_accuracy: 0.8691 - val_loss: 0.4332\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8247 - loss: 0.5421 - val_accuracy: 0.8356 - val_loss: 0.4091\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7788 - loss: 0.5573 - val_accuracy: 0.8725 - val_loss: 0.3369\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8334 - loss: 0.3975 - val_accuracy: 0.8993 - val_loss: 0.2333\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8404 - loss: 0.3564 - val_accuracy: 0.9094 - val_loss: 0.1914\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8581 - loss: 0.3130 - val_accuracy: 0.9060 - val_loss: 0.1711\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8595 - loss: 0.2791 - val_accuracy: 0.9161 - val_loss: 0.1573\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8954 - loss: 0.2237 - val_accuracy: 0.9228 - val_loss: 0.1377\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9056 - loss: 0.2003 - val_accuracy: 0.9295 - val_loss: 0.1192\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9198 - loss: 0.1856 - val_accuracy: 0.9295 - val_loss: 0.1178\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8950 - loss: 0.2045 - val_accuracy: 0.9329 - val_loss: 0.1116\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9220 - loss: 0.1778 - val_accuracy: 0.9430 - val_loss: 0.1061\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9226 - loss: 0.1587 - val_accuracy: 0.9530 - val_loss: 0.0942\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9396 - loss: 0.1325 - val_accuracy: 0.9530 - val_loss: 0.0888\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9209 - loss: 0.1525 - val_accuracy: 0.9698 - val_loss: 0.0677\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9305 - loss: 0.1242 - val_accuracy: 0.9698 - val_loss: 0.0675\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9380 - loss: 0.1333 - val_accuracy: 0.9866 - val_loss: 0.0497\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9450 - loss: 0.1229 - val_accuracy: 0.9866 - val_loss: 0.0413\n"
     ]
    }
   ],
   "source": [
    "historyConv = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "186cff56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">1,372</span> \n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2401</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,728</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m49\u001b[0m)                \u001b[38;5;34m1,372\u001b[0m \n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2401\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m153,728\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                         \u001b[38;5;34m325\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466,277</span> (1.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m466,277\u001b[0m (1.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">155,425</span> (607.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m155,425\u001b[0m (607.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,852</span> (1.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m310,852\u001b[0m (1.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0854e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historyConv.history['accuracy'], label='Train')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0.85, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af06fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - 5ms/step - accuracy: 0.9866 - loss: 0.0413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.041261203587055206, 0.9865771532058716]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "867e603c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0.16422342, 0.29629984, 0.16110013, 0.21880186, 0.15957476],\n",
       "       [0.40460956, 0.1488476 , 0.14884762, 0.1488476 , 0.1488476 ],\n",
       "       [0.14884761, 0.14884768, 0.14884761, 0.40460947, 0.14884761],\n",
       "       [0.14884824, 0.14885074, 0.14884831, 0.40460443, 0.14884824],\n",
       "       [0.14884827, 0.14884827, 0.14885096, 0.14884827, 0.40460417]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model = keras.Sequential([model, keras.layers.Softmax()])\n",
    "probability_model(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4b46914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea9053f946144f9ba74535b118ed5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Image index:', max=297), Output()), _dom_classes=('widge"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "label_names = ['Character (FORWARD)', 'Monster', 'Food', 'Item', 'Character (SIDE)']\n",
    "index_slider = widgets.IntSlider(value=0, min=0, max=len(X_test)-1, description='Image index:')\n",
    "def show_image(index):\n",
    "    plt.imshow(X_test[index])\n",
    "    plt.show()\n",
    "    prediction = probability_model(X_test[index:index+1]).numpy()\n",
    "    print(f'Predicted label: {np.argmax(prediction)} ({label_names[np.argmax(prediction)]})')\n",
    "    print(f'Actual label: {np.argmax(y_test[index])} ({label_names[np.argmax(y_test[index])]})')\n",
    "    print('Predicted probabilities:')\n",
    "    print(f'    Character (FORWARD): {'%.2f' % (prediction[0][0] * 100)}%')\n",
    "    print(f'    Monster:             {'%.2f' % (prediction[0][1] * 100)}%')\n",
    "    print(f'    Food:                {'%.2f' % (prediction[0][2] * 100)}%')\n",
    "    print(f'    Item:                {'%.2f' % (prediction[0][3] * 100)}%')\n",
    "    print(f'    Character (SIDE):    {'%.2f' % (prediction[0][4] * 100)}%')\n",
    "widgets.interactive(show_image, index=index_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7f7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4890 - loss: 1.3008\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6544 - loss: 0.8374\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8503 - loss: 0.5031\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8995 - loss: 0.3251\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9543 - loss: 0.2084\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9680 - loss: 0.1540\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9738 - loss: 0.1009\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9709 - loss: 0.1141 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0706\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0583\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0505\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0354\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0243\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0254\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0281\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0230\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0160\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0151\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.0206\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0155\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0145\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0183\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0161\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0118\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0088\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0067\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0065\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0088\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0090\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0062\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0053\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9975 - loss: 0.0064\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0026   \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0033   \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0035   \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Accuracy:  1.0\n",
      "0.978969 (0.016322) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.983180 (0.012643) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "0.974759 (0.015775) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.976864 (0.015488) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.974759 (0.014301) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "0.974759 (0.019540) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "0.976864 (0.010341) with: {'batch_size': 32, 'epochs': 150, 'optimizer': 'Adam'}\n",
      "0.978969 (0.011551) with: {'batch_size': 32, 'epochs': 150, 'optimizer': 'Adadelta'}\n",
      "0.978969 (0.011551) with: {'batch_size': 32, 'epochs': 150, 'optimizer': 'SGD'}\n",
      "0.974781 (0.010752) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.981075 (0.013978) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "0.978969 (0.011551) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.974781 (0.008443) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.976864 (0.018126) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "0.978969 (0.011551) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "0.978969 (0.013332) with: {'batch_size': 50, 'epochs': 150, 'optimizer': 'Adam'}\n",
      "0.976864 (0.015488) with: {'batch_size': 50, 'epochs': 150, 'optimizer': 'Adadelta'}\n",
      "0.976886 (0.013972) with: {'batch_size': 50, 'epochs': 150, 'optimizer': 'SGD'}\n",
      "0.972675 (0.008454) with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.976864 (0.010341) with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "0.972654 (0.012661) with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.978969 (0.011551) with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.976864 (0.012298) with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "0.978969 (0.011551) with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "0.981075 (0.012291) with: {'batch_size': 100, 'epochs': 150, 'optimizer': 'Adam'}\n",
      "0.976864 (0.012298) with: {'batch_size': 100, 'epochs': 150, 'optimizer': 'Adadelta'}\n",
      "0.978969 (0.009440) with: {'batch_size': 100, 'epochs': 150, 'optimizer': 'SGD'}\n",
      "Best: 0.983180 using {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adadelta'}\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def create_model(optimizer=\"adam\"):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,3)))\n",
    "    model.add(keras.layers.Flatten(input_shape=(16, 16, 3)))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "   \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "'''\n",
    "param_grid = {\n",
    "    'epochs' : [50, 100, 150],\n",
    "    'batch_size' : [32, 50, 100],\n",
    "    'optimizer' : ['Adam', 'Adadelta', 'SGD']\n",
    "}\n",
    "\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_cv, param_distributions=param_grid, n_iter=15\n",
    ")\n",
    "\n",
    "random_model = random_search.fit(X,y)\n",
    "\n",
    "start = time()\n",
    "print(\n",
    "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
    "    % ((time() - start), 15)\n",
    ")\n",
    "report(random_search.cv_results_)\n",
    "'''\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'epochs' : [50, 100, 150],\n",
    "    'batch_size' : [32, 50, 100],\n",
    "    'optimizer' : ['Adam', 'Adadelta', 'SGD']\n",
    "}\n",
    "\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "grid = GridSearchCV(estimator=model_cv,  \n",
    "                    n_jobs=-1, \n",
    "                    verbose=1,\n",
    "                    cv=5,\n",
    "                    param_grid=param_grid)\n",
    "\n",
    "grid_cv_model = grid.fit(X_cv, y_cv,)\n",
    "\n",
    "y_pred = grid_cv_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \", np.mean(y_test == y_pred))\n",
    "\n",
    "means = grid_cv_model.cv_results_['mean_test_score'] # Mean of test scores\n",
    "stds = grid_cv_model.cv_results_['std_test_score'] # standard deviations of test scores\n",
    "params = grid_cv_model.cv_results_['params'] # parameters used\n",
    "# to print all scores, standard deviations and parameters used\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Printing the Best Parameters as a Result of Grid Search Cross Validation on the Screen\n",
    "print(\"Best: %f using %s\" % (grid_cv_model.best_score_, grid_cv_model.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eeb99aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4624 - loss: 1.3331 \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7581 - loss: 0.7388 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9025 - loss: 0.3823\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 0.2316\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.1658\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.1054\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9712 - loss: 0.1004  \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.1106 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0753 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0445 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0499 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0296 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0331 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0257 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0177 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0131 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0175  \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0133\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0108 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0081 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0088\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0095 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0185 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0100 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0080  \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0120 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0098\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0092 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0044 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0087\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0090\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0048  \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0086\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028     \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0049 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0017 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4953 - loss: 1.3240\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7135 - loss: 0.7676\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.4526 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9473 - loss: 0.2141\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9702 - loss: 0.1766\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1530 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9671 - loss: 0.1126\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9790 - loss: 0.0904  \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0486\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0503  \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0410 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0468 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0479 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0278 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9983 - loss: 0.0206\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0213 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0159 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0147\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0108 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0114 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0116 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0115 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0127 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0085 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0089 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0051 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0076 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0108  \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0056 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0073 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0053 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0044\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0029    \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0033   \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0081\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0054 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0065 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0032 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034     \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018    \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5327 - loss: 1.3197\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.7823 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8803 - loss: 0.4149\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9358 - loss: 0.2619 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.1927  \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1573 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.1076\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0691 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0649 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0532 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0393 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0278 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0192 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0198 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0152\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0142\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0133  \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0129\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0130 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0145\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0103\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0124\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0086\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0146\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0064\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0055\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0044\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0020    \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017    \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5358 - loss: 1.2614\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7366 - loss: 0.7192\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9109 - loss: 0.3389\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9298 - loss: 0.2158\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.1393 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.1005\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0980\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9903 - loss: 0.0627\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0570\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0356\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0275\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0219\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0169\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0190\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0148\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0137 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0144\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0103\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0125\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0086\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0064\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0120\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0097\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0059 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0084 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0025    \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0049  \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0027     \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.9309e-04 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4622e-04 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0010   \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.9745e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017   \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4880 - loss: 1.3587\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 0.8773 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8123 - loss: 0.5371 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8989 - loss: 0.3399 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9287 - loss: 0.2145  \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.1219\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0778 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0549 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0528 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0360\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0399 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0305\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0259\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0233\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0156\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0129\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0113\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0133\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0107\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0075\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0089\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0079  \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0084\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0053 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0044\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0078  \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0075   \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0101\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0157\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.7641e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    }
   ],
   "source": [
    "#cross val with grid cv\n",
    "\n",
    "'''\n",
    "random_cv_model = random_model.best_estimator_\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(random_cv_model, X_cv, np.argmax(y_test, axis=1), cv=kfold,scoring= 'accuracy')\n",
    "\n",
    "'''\n",
    "cv_model = grid_cv_model.best_estimator_\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "#np.argmax(y_test, axis=1)\n",
    "\n",
    "predicted_labels = []\n",
    "\n",
    "\n",
    "\n",
    "results = cross_val_score(cv_model, X,y, cv=kfold,scoring= 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7c5ad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Cross Validation Accuracy Results:  [0.99159664 0.98319328 0.99159664 0.99159664 0.98319328]\n",
      "K-fold Cross Validation Accuracy Results Mean:  0.9882352941176471\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "y_test shape: (119, 5)\n",
      "y_pred shape: (476, 5)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5948 - loss: 1.1320\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7376 - loss: 0.7178\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7884 - loss: 0.4902\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8786 - loss: 0.3339\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.2237\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9590 - loss: 0.1423\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 0.1260\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9836 - loss: 0.0942\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0593\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9832 - loss: 0.0552\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0313\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0397\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9934 - loss: 0.0315\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0198\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0250\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0306\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0211\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0127\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0130\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0093\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0163\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0093\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0062\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0086\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0132\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0106\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0047\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0059\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0064\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0023   \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0031   \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0075\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0020   \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6469 - loss: 1.0627\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8551 - loss: 0.3684\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9905 - loss: 0.1094\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 0.1072\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0727\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 0.0361\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0171\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0181\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0232\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0158\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0124\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0094\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0075\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0070\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0044\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019   \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017    \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0010    \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.1353e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0025    \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.2360e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.0906e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.8863e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.5464e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8131e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.1510e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.7337e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011    \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.0976e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.2764e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.6951e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.6852e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.9149e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8640e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.3750e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.3025e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.4794e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.6869e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4470 - loss: 1.3104\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 0.6393\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9328 - loss: 0.3200\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9726 - loss: 0.1897\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.1636\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0828\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.0639\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 0.0663\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0386\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0334\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0258\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.0185\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0226\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0253\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0165\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0124\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0122\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0073\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0085\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0093\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0025   \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0042\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0034\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0036   \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019   \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0025   \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0015   \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.7416e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0017    \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.4521e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4751 - loss: 1.3630\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.6904\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9510 - loss: 0.2791\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9694 - loss: 0.1570\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.1214\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9902 - loss: 0.0765\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.0511\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 0.0405\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0385\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0300\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0221\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0160\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0141\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0094\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0101\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0064\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0089\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0051\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0088\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0056\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0056\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0067\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0019   \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0016    \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0014   \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0023    \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0010   \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjbea\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\cjbea\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4533 - loss: 1.3939\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8230 - loss: 0.7044\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8866 - loss: 0.4196\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.2115\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9656 - loss: 0.1399\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9783 - loss: 0.0982\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9745 - loss: 0.0874\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.0752\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0478\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0378 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0286\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 0.0216\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0213\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0168\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0141\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0134\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0099\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0178\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0137\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0231\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0084\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0072\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0067\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0077\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0066\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0056\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0055\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0067\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0014    \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Evaluate on test set:  0.8252100840336134\n"
     ]
    }
   ],
   "source": [
    "#print kfold results\n",
    "print('K-fold Cross Validation Accuracy Results: ', results)\n",
    "print('K-fold Cross Validation Accuracy Results Mean: ', results.mean())\n",
    "\n",
    "\n",
    "y_pred = cv_model.predict(X_cv)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "y_test_int = y_test.astype(int) #make sure y_test and y_pred are compatible\n",
    "test_acc = cross_val_score(cv_model, X, y, scoring = 'accuracy')\n",
    "print('Evaluate on test set: ', np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef10a50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 32x32; Received: input_shape=(16, 16, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#evaluating acc of resNet50 model compaired to our model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m resNet50Model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m resNet50Model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m     16\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\keras\\src\\applications\\resnet.py:406\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    403\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack_residual_blocks_v1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack_residual_blocks_v1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\keras\\src\\applications\\resnet.py:125\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using `weights=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` with `include_top=True`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`classes` should be 1000.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived classes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m     )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[43mimagenet_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobtain_input_shape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_flatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     img_input \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_shape)\n",
      "File \u001b[1;32m~\\Lib\\site-packages\\keras\\src\\applications\\imagenet_utils.py:390\u001b[0m, in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input must have 3 channels; Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`input_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m                 )\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    388\u001b[0m                 input_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m min_size\n\u001b[0;32m    389\u001b[0m             ) \u001b[38;5;129;01mor\u001b[39;00m (input_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m min_size):\n\u001b[1;32m--> 390\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    391\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput size must be at least \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    393\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    394\u001b[0m                 )\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m require_flatten:\n",
      "\u001b[1;31mValueError\u001b[0m: Input size must be at least 32x32; Received: input_shape=(16, 16, 3)"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#evaluating acc of resNet50 model compaired to our model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "resNet50Model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(16, 16, 3),\n",
    "    pooling=None,\n",
    "    classes=5,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "for layer in resNet50Model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "dnn_model = keras.models.Sequential()\n",
    "dnn_model.add(resNet50Model)\n",
    "dnn_model.add(keras.layers.Flatten())\n",
    "dnn_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "dnn_model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "dnn_model.summary()\n",
    "dnn_model.compile(optimizer=keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "resnetHistory = dnn_model.fit(X_train, validation_data = X_test, epochs = 20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979246b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
