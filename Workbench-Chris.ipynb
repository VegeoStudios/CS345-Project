{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee19a590",
   "metadata": {},
   "source": [
    "-[Cross validation using grid search](https://www.kaggle.com/code/muhammetvarl/keras-multiclass-classification-cross-validation)\n",
    "\n",
    "-[resnet50Docs](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ff7b10-6629-4374-9399-e2df4a0cb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import scipy.signal\n",
    "import keras\n",
    "import ipywidgets as widgets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219b7d07-c5d3-4624-85ad-22391975a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89400, 5)\n",
      "(89400, 16, 16, 3)\n",
      "(595, 5)\n",
      "(595, 16, 16, 3)\n",
      "[[[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 99  27  79]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 76  20  55]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 76  20  55]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 97  65  41]\n",
      "   ...\n",
      "   [ 97  65  41]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 73  49  31]\n",
      "   ...\n",
      "   [ 73  49  31]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [ 36  24  15]\n",
      "   [ 73  49  31]\n",
      "   ...\n",
      "   [ 73  49  31]\n",
      "   [ 36  24  15]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 209  69]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 209  69]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 37  37  37]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [230  34  34]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [230  34  34]\n",
      "   [  0   0   0]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [ 37  37  37]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [  0   0   0]\n",
      "   [136  95  51]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [ 13  13  13]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.load('./Dataset1/sprites_labels.npy')\n",
    "sprites = np.load('./Dataset1/sprites.npy')\n",
    "\n",
    "print(data.shape)\n",
    "print(sprites.shape)\n",
    "\n",
    "selected_data = data[:894]\n",
    "selected_data = np.delete(selected_data, slice(244, 543), axis=0) #deletes duplicates\n",
    "print(selected_data.shape)\n",
    "\n",
    "selected_sprites = sprites[:894]\n",
    "selected_sprites = np.delete(selected_sprites, slice(244, 543), axis=0) #deletes duplicates\n",
    "print(selected_sprites.shape)\n",
    "\n",
    "data_with_mirrored = np.concatenate((selected_data, selected_data), axis=0)\n",
    "\n",
    "mirrored_sprites = np.flip(selected_sprites, axis=2)\n",
    "sprites_with_mirrored = np.concatenate((selected_sprites, mirrored_sprites), axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(selected_sprites[1])\n",
    "ax[1].imshow(mirrored_sprites[1]);\n",
    "\n",
    "print(sprites_with_mirrored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03821100-10bd-4767-bebd-f04bfb5d37e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sprites_with_mirrored, data_with_mirrored)\n",
    "\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, 5)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, 5)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "\n",
    "conv_result = scipy.signal.convolve2d(X_train[400, :, :, :1].reshape(16, 16), np.array([[1,2,1],[0,0,0],[-1,-2,-1]]).T)\n",
    "im = ax.imshow(conv_result, cmap='Greys')\n",
    "ax2.imshow(X_train[400, :, :, :1])\n",
    "ax.axis('off')\n",
    "fig.colorbar(im, ax=[ax, ax2]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bf0d9f-481e-4ec2-b77a-9a0c06d5efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "conv_network = tf.keras.Sequential()\n",
    "\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,1)))\n",
    "conv_network.add(tf.keras.layers.Flatten())\n",
    "\n",
    "conv_network.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "conv_network.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data1 = np.load('./Dataset1/sprites_labels.npy')\n",
    "sprites1 = np.load('./Dataset1/sprites.npy')\n",
    "\n",
    "selected_labels = data1[:894]\n",
    "y = np.delete(selected_labels, slice(244, 543), axis=0)\n",
    "\n",
    "selected_sprites = sprites1[:894]\n",
    "X = np.delete(selected_sprites, slice(244, 543), axis=0)\n",
    "\n",
    "X = X.astype(np.float32) / 255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b004bea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,3)),\n",
    "    #keras.layers.Conv2D(196, (3, 3), strides=(1,1), activation='relu', input_shape=(16,16,3)),\n",
    "    keras.layers.Flatten(input_shape=(16, 16, 3)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "]);\n",
    "\n",
    "#other activations functions tried include sigmoid and different orders of relu and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52014fd3-cadd-45b2-805c-dd325ee47c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.2021492e-04 9.9905068e-01 4.2339247e-14 6.2902976e-04 4.9211991e-14]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model(X_train[:1]).numpy()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181fd53c-b0d8-43a9-80c5-21efb0b9377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14893138, 0.40432382, 0.1488837 , 0.14897738, 0.1488837 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37e5b09-a018-4b7b-a0a1-cc6736fe2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.CategoricalCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea37ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.3713317"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd1453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "loss_fn1 = keras.losses.CategoricalFocalCrossentropy()\n",
    "loss_fn1(y_train[:1], predictions).numpy()\n",
    "'''\n",
    "\n",
    "#loss_fn2 = keras.losses.SparseCategoricalCrossentropy()\n",
    "#loss_fn2(y_train[:2], predictions).numpy()\n",
    "\n",
    "model.compile(optimizer='Adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "#Tried with RMSProp, SGD, Adadelta. Adam appears to have the most acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce19adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4508 - loss: 40.3200 - val_accuracy: 0.6644 - val_loss: 3.0776\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6825 - loss: 2.7357 - val_accuracy: 0.8221 - val_loss: 0.6728\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7679 - loss: 0.7706 - val_accuracy: 0.8221 - val_loss: 0.4380\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.4956 - val_accuracy: 0.8557 - val_loss: 0.3587\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 0.3448 - val_accuracy: 0.8826 - val_loss: 0.2654\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.2318 - val_accuracy: 0.8993 - val_loss: 0.2032\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.2275 - val_accuracy: 0.9295 - val_loss: 0.1828\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9360 - loss: 0.1746 - val_accuracy: 0.9295 - val_loss: 0.1845\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9401 - loss: 0.1468 - val_accuracy: 0.9463 - val_loss: 0.1546\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 0.1337 - val_accuracy: 0.9530 - val_loss: 0.1507\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9514 - loss: 0.1195 - val_accuracy: 0.9530 - val_loss: 0.1348\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.0823 - val_accuracy: 0.9664 - val_loss: 0.1116\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9587 - loss: 0.1047 - val_accuracy: 0.9698 - val_loss: 0.1179\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9725 - loss: 0.0738 - val_accuracy: 0.9732 - val_loss: 0.1109\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.0818 - val_accuracy: 0.9698 - val_loss: 0.1132\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9621 - loss: 0.0836 - val_accuracy: 0.9631 - val_loss: 0.1312\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9759 - loss: 0.0701 - val_accuracy: 0.9597 - val_loss: 0.1286\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9571 - loss: 0.1036 - val_accuracy: 0.9698 - val_loss: 0.0927\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9590 - loss: 0.0871 - val_accuracy: 0.9698 - val_loss: 0.0826\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9822 - loss: 0.0539 - val_accuracy: 0.9765 - val_loss: 0.0873\n"
     ]
    }
   ],
   "source": [
    "historyConv = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "186cff56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2401</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">153,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m49\u001b[0m)       │         \u001b[38;5;34m1,372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2401\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m153,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466,277</span> (1.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m466,277\u001b[0m (1.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">155,425</span> (607.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m155,425\u001b[0m (607.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,852</span> (1.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m310,852\u001b[0m (1.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0854e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historyConv.history['accuracy'], label='Train')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim([0.85, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af06fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - 3ms/step - accuracy: 0.9765 - loss: 0.0873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0872504860162735, 0.9765100479125977]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "867e603c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0.15548107, 0.17028733, 0.34521088, 0.15814298, 0.17087765],\n",
       "       [0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758],\n",
       "       [0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758],\n",
       "       [0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758],\n",
       "       [0.14884758, 0.14884758, 0.14884758, 0.40460962, 0.14884758]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model = keras.Sequential([model, keras.layers.Softmax()])\n",
    "probability_model(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4b46914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311b78222a1b4fb594886dd10ea8c20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Image index:', max=297), Output()), _dom_classes=('widge…"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "label_names = ['Character (FORWARD)', 'Monster', 'Food', 'Item', 'Character (SIDE)']\n",
    "index_slider = widgets.IntSlider(value=0, min=0, max=len(X_test)-1, description='Image index:')\n",
    "def show_image(index):\n",
    "    plt.imshow(X_test[index])\n",
    "    plt.show()\n",
    "    prediction = probability_model(X_test[index:index+1]).numpy()\n",
    "    print(f'Predicted label: {np.argmax(prediction)} ({label_names[np.argmax(prediction)]})')\n",
    "    print(f'Actual label: {np.argmax(y_test[index])} ({label_names[np.argmax(y_test[index])]})')\n",
    "    print('Predicted probabilities:')\n",
    "    print(f'    Character (FORWARD): {'%.2f' % (prediction[0][0] * 100)}%')\n",
    "    print(f'    Monster:             {'%.2f' % (prediction[0][1] * 100)}%')\n",
    "    print(f'    Food:                {'%.2f' % (prediction[0][2] * 100)}%')\n",
    "    print(f'    Item:                {'%.2f' % (prediction[0][3] * 100)}%')\n",
    "    print(f'    Character (SIDE):    {'%.2f' % (prediction[0][4] * 100)}%')\n",
    "widgets.interactive(show_image, index=index_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7f7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4914 - loss: 1.3961  \n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6363 - loss: 0.9572 \n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7496 - loss: 0.7185 \n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8804 - loss: 0.4913 \n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9186 - loss: 0.3701 \n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.2361 \n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9609 - loss: 0.1990 \n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9520 - loss: 0.1502 \n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9731 - loss: 0.1254 \n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.1275 \n",
      "Epoch 11/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9760 - loss: 0.0814 \n",
      "Epoch 12/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9889 - loss: 0.0580 \n",
      "Epoch 13/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0507 \n",
      "Epoch 14/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9877 - loss: 0.0520 \n",
      "Epoch 15/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0411 \n",
      "Epoch 16/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9933 - loss: 0.0370 \n",
      "Epoch 17/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0278 \n",
      "Epoch 18/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9955 - loss: 0.0386 \n",
      "Epoch 19/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9887 - loss: 0.0554 \n",
      "Epoch 20/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0296 \n",
      "Epoch 21/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0216 \n",
      "Epoch 22/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0154 \n",
      "Epoch 23/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0118 \n",
      "Epoch 24/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0151 \n",
      "Epoch 25/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0102 \n",
      "Epoch 26/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0145 \n",
      "Epoch 27/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 \n",
      "Epoch 28/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0111 \n",
      "Epoch 29/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0179 \n",
      "Epoch 30/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0127 \n",
      "Epoch 31/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0076 \n",
      "Epoch 32/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0077 \n",
      "Epoch 33/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0100 \n",
      "Epoch 34/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0078 \n",
      "Epoch 35/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 36/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0096 \n",
      "Epoch 37/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0095 \n",
      "Epoch 38/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0055 \n",
      "Epoch 39/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056 \n",
      "Epoch 40/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 41/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 42/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0065 \n",
      "Epoch 43/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 44/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0034 \n",
      "Epoch 45/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
      "Epoch 46/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0045 \n",
      "Epoch 47/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0046 \n",
      "Epoch 48/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 49/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 50/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0031     \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Accuracy:  0.9958333333333333\n",
      "0.973684 (0.027600) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.976316 (0.015345) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "0.978947 (0.024404) with: {'batch_size': 32, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.978947 (0.021379) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.976316 (0.024119) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "0.978947 (0.024404) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "0.973684 (0.027600) with: {'batch_size': 32, 'epochs': 150, 'optimizer': 'Adam'}\n",
      "0.976316 (0.025514) with: {'batch_size': 32, 'epochs': 150, 'optimizer': 'Adadelta'}\n",
      "0.973684 (0.018608) with: {'batch_size': 32, 'epochs': 150, 'optimizer': 'SGD'}\n",
      "0.971053 (0.028098) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.968421 (0.030689) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "0.976316 (0.024119) with: {'batch_size': 50, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.978947 (0.021379) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.976316 (0.025514) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "0.976316 (0.029304) with: {'batch_size': 50, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "0.971053 (0.029304) with: {'batch_size': 50, 'epochs': 150, 'optimizer': 'Adam'}\n",
      "0.973684 (0.023538) with: {'batch_size': 50, 'epochs': 150, 'optimizer': 'Adadelta'}\n",
      "0.976316 (0.029304) with: {'batch_size': 50, 'epochs': 150, 'optimizer': 'SGD'}\n",
      "0.963158 (0.021053) with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "0.957895 (0.028098) with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "0.957895 (0.025514) with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "0.976316 (0.022638) with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "0.968421 (0.033906) with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "0.976316 (0.025514) with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "0.976316 (0.025514) with: {'batch_size': 100, 'epochs': 150, 'optimizer': 'Adam'}\n",
      "0.973684 (0.022017) with: {'batch_size': 100, 'epochs': 150, 'optimizer': 'Adadelta'}\n",
      "0.973684 (0.027600) with: {'batch_size': 100, 'epochs': 150, 'optimizer': 'SGD'}\n",
      "Best: 0.978947 using {'batch_size': 32, 'epochs': 50, 'optimizer': 'SGD'}\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def create_model(optimizer, add_conv_layer, lossFunction):\n",
    "    model = keras.models.Sequential()\n",
    "    if(add_conv_layer):\n",
    "        model.add(keras.layers.Conv2D(49, (3, 3), strides=(2,2), activation='relu', input_shape=(16,16,3)))\n",
    "    model.add(keras.layers.Flatten(input_shape=(16, 16, 3)))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "   \n",
    "    model.compile(loss= lossFunction, optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "'''\n",
    "resNet50Model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(16, 16, 3),\n",
    "    pooling=None,\n",
    "    classes=5,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "for layer in resNet50Model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "dnn_model = keras.models.Sequential()\n",
    "dnn_model.add(resNet50Model)\n",
    "dnn_model.add(keras.layers.Flatten())\n",
    "dnn_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "dnn_model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "'''\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.2, random_state=43, shuffle=True)\n",
    "\n",
    "'''\n",
    "param_grid = {\n",
    "    'epochs' : [50, 100, 150],\n",
    "    'batch_size' : [32, 50, 100],\n",
    "    'optimizer' : ['Adam', 'Adadelta', 'SGD']\n",
    "}\n",
    "\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_cv, param_distributions=param_grid, n_iter=15\n",
    ")\n",
    "\n",
    "random_model = random_search.fit(X,y)\n",
    "\n",
    "start = time()\n",
    "print(\n",
    "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
    "    % ((time() - start), 15)\n",
    ")\n",
    "report(random_search.cv_results_)\n",
    "'''\n",
    "\n",
    "'''\n",
    " 'epochs' : [50, 100, 150],\n",
    "'batch_size' : [32, 50, 100],\n",
    "'''\n",
    "param_grid = {\n",
    "    'epochs' : [50, 150],\n",
    "    'batch_size' : [32, 100],\n",
    "    'optimizer' : ['Adam', 'Adadelta', 'SGD'],\n",
    "    'add_conv_layer' : [True, False],\n",
    "    'loss' : ['MSE', 'categorical_crossentropy', 'sparse_categorical_crossentropy']\n",
    "}\n",
    "\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "grid = GridSearchCV(estimator=model_cv,  \n",
    "                    n_jobs=-1, \n",
    "                    verbose=1,\n",
    "                    cv=5,\n",
    "                    param_grid=param_grid)\n",
    "\n",
    "grid_cv_model = grid.fit(X_train, y_train,)\n",
    "\n",
    "y_pred = grid_cv_model.predict(X_validate)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \", np.mean(y_validate == y_pred))\n",
    "\n",
    "means = grid_cv_model.cv_results_['mean_test_score'] # Mean of test scores\n",
    "stds = grid_cv_model.cv_results_['std_test_score'] # standard deviations of test scores\n",
    "params = grid_cv_model.cv_results_['params'] # parameters used\n",
    "# to print all scores, standard deviations and parameters used\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Printing the Best Parameters as a Result of Grid Search Cross Validation on the Screen\n",
    "print(\"Best: %f using %s\" % (grid_cv_model.best_score_, grid_cv_model.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeb99aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5098 - loss: 1.2675  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7550 - loss: 0.6372 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.3126 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.2032 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1622 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1256 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9720 - loss: 0.1006 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9876 - loss: 0.0616 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9767 - loss: 0.0758 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0447 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9976 - loss: 0.0272 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0213 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9921 - loss: 0.0308 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9933 - loss: 0.0277 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0192 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0113 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0125 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0111 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0069 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0087 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0066 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0059 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037     \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0067 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0058 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0057 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0075 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029     \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0086     \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0054 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5227 - loss: 1.2328  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7146 - loss: 0.7835 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8540 - loss: 0.4368 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2683 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1738 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9852 - loss: 0.1081 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9766 - loss: 0.1054 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9786 - loss: 0.0846 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9820 - loss: 0.0649 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0417 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0316 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0357 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0317 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9919 - loss: 0.0422 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0246 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0196 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0213 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0237 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0139 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0121 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0089 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0106 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0152 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0149 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0083 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0095 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0071 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0085 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0043 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0047 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030     \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031     \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0051     \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000203C561C720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4791 - loss: 1.3185  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8191 - loss: 0.5854 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9284 - loss: 0.2670 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1386 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.1051 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0568 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0412 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9893 - loss: 0.0387 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9923 - loss: 0.0406 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0207 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0143 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0109 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0148 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0160 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0116 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0115 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0091 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0131 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0107 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0060 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0063 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0101 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.7584e-04 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0025     \n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000203C54DAAC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5128 - loss: 1.3246  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7493 - loss: 0.7105 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.3709 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.2083 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9657 - loss: 0.1636 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9633 - loss: 0.1306 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9862 - loss: 0.0805 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9951 - loss: 0.0601 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9893 - loss: 0.0697 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0354 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0361 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0269 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9921 - loss: 0.0311 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0217 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0152 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0149 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0212 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0232 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0186 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0111 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0099 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0065 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0079 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0044 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0066 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0046 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0041 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020     \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5752 - loss: 1.2388  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7487 - loss: 0.6823 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8957 - loss: 0.3453 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1907 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9752 - loss: 0.1168 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0764 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.0785 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0404 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0389 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0336 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0272 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0280 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0225 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0203 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0252 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0136 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0107 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0157 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0091 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0114 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0080 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0085 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0127 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0093 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0140 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0034     \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "#cross val with grid cv\n",
    "\n",
    "'''\n",
    "random_cv_model = random_model.best_estimator_\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(random_cv_model, X_cv, np.argmax(y_test, axis=1), cv=kfold,scoring= 'accuracy')\n",
    "\n",
    "'''\n",
    "cv_model = grid_cv_model.best_estimator_\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "results = cross_val_score(cv_model, X,y, cv=kfold,scoring= 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7c5ad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Cross Validation Accuracy Results:  [0.98319328 0.99159664 0.99159664 0.97478992 0.98319328]\n",
      "K-fold Cross Validation Accuracy Results Mean:  0.984873949579832\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "X_train shape:  (380, 16, 16, 3)\n",
      "y_test shape: (119, 5)\n",
      "y_validate shape: (96, 5)\n",
      "y_pred shape: (380, 5)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6740 - loss: 1.0968  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7086 - loss: 0.7270 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8311 - loss: 0.4107 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2415 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9826 - loss: 0.1391 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0993 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0594 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0506 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0399 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0332 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0252 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0170 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0145 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0159 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0109 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0108 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0101 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0102 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0084 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0077 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0072 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0060 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0112 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0105 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020     \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0046 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027     \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017     \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6050 - loss: 1.0559  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.4478 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2835 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9816 - loss: 0.1254 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9865 - loss: 0.0915 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9832 - loss: 0.0755 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.0741 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9873 - loss: 0.0485 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9918 - loss: 0.0363 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9901 - loss: 0.0352 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0268 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0157 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0197 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0147 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0088 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0067 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0094 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0058 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0064 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0151 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0063 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032     \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029     \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0172     \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0068 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0089 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017     \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018     \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012     \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0024     \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0060 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012     \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0054 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0033 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6154e-04 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4214 - loss: 1.3886   \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6421 - loss: 0.9070 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.4287 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.3010 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9575 - loss: 0.1775 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9793 - loss: 0.1136 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9836 - loss: 0.0982 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0638 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0447 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0524 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9860 - loss: 0.0489 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0363 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0206 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0307 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0294 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0148 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0142 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0174 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0135 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0096 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0139 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0087 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0063 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0104 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0066 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0057 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0045 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0046 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037     \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0038 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4232 - loss: 1.4141   \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.7834 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.4485 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.2297 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1479 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.1206 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9876 - loss: 0.0790 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0701 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0429 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0377 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0248 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0280 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0222 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0177 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0125 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0157 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0168 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0112 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0126 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0109 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0101 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0068 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0090 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0098 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0074 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048     \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0055 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019     \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4682 - loss: 1.3844  \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.8660 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8862 - loss: 0.4685 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.3041 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.1817 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.1423 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.1227 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0767 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9844 - loss: 0.0816 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0601 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0524 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0368 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0362 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0261 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0188 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0168 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0166 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0278 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0128 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0189 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0183 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0136 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0082 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0076 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0124 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0088 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0080 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0081 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0132 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0139 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0047 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0024 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0049 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0045 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0050 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0037 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Evaluate on test set:  0.8184873949579833\n"
     ]
    }
   ],
   "source": [
    "#print kfold results\n",
    "print('K-fold Cross Validation Accuracy Results: ', results)\n",
    "print('K-fold Cross Validation Accuracy Results Mean: ', results.mean())\n",
    "\n",
    "\n",
    "y_pred = cv_model.predict(X_train)\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"y_validate shape:\", y_validate.shape)\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "y_test_int = y_test.astype(int) #make sure y_test and y_pred are compatible\n",
    "test_acc = cross_val_score(cv_model, X, y, scoring = 'accuracy')\n",
    "print('Evaluate on test set: ', np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef10a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#evaluating acc of resNet50 model compaired to our model\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\\n\\nresNet50Model = tf.keras.applications.ResNet50(\\n    include_top=False,\\n    weights='imagenet',\\n    input_tensor=None,\\n    input_shape=(16, 16, 3),\\n    pooling=None,\\n    classes=5,\\n    classifier_activation='softmax'\\n)\\n\\nfor layer in resNet50Model.layers:\\n    layer.trainable=False\\n    \\ndnn_model = keras.models.Sequential()\\ndnn_model.add(resNet50Model)\\ndnn_model.add(keras.layers.Flatten())\\ndnn_model.add(keras.layers.Dense(512, activation='relu'))\\ndnn_model.add(keras.layers.Dense(5, activation='softmax'))\\n\\ndnn_model.summary()\\ndnn_model.compile(optimizer=keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\\n\\n\\nresnetHistory = dnn_model.fit(X_train, validation_data = X_test, epochs = 20)\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#evaluating acc of resNet50 model compaired to our model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "resNet50Model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(16, 16, 3),\n",
    "    pooling=None,\n",
    "    classes=5,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "for layer in resNet50Model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "dnn_model = keras.models.Sequential()\n",
    "dnn_model.add(resNet50Model)\n",
    "dnn_model.add(keras.layers.Flatten())\n",
    "dnn_model.add(keras.layers.Dense(512, activation='relu'))\n",
    "dnn_model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "dnn_model.summary()\n",
    "dnn_model.compile(optimizer=keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "resnetHistory = dnn_model.fit(X_train, validation_data = X_test, epochs = 20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979246b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
